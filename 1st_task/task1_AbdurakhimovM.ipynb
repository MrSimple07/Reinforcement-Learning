{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oNPjDBdpy8um"
      },
      "source": [
        "# Minigrid UnlockEnv PPO Experiment\n",
        "\n",
        "Muslimbek Abdurakhimov\n",
        "\n",
        "env: Unlock    \n",
        "\n",
        "parameter: vf_coef: float = [0.5->1.0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVe0kMXXy8up"
      },
      "source": [
        "# Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8d12HZ_y8uq"
      },
      "source": [
        "This notebook summarizes our experiments with the Proximal Policy Optimization (PPO) algorithm on the Minigrid UnlockEnv environment. We investigated the effect of different vf_coef values on the agent's performance."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing libraries"
      ],
      "metadata": {
        "id": "j7ASuDm70EIt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "DdJyKyWO0HxC"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tFsSV2u3y8ur"
      },
      "outputs": [],
      "source": [
        "import gymnasium as gym\n",
        "import torch as th\n",
        "import torch.nn as nn\n",
        "from minigrid import __version__ as minigrid_version\n",
        "from minigrid.wrappers import ImgObsWrapper\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv, VecTransposeImage\n",
        "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
        "from stable_baselines3.common.callbacks import EvalCallback, StopTrainingOnRewardThreshold\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yy9LLsrOy8us",
        "outputId": "5cd42eec-1085-467e-a34f-8a79cf46d07e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Minigrid version: 2.3.1\n",
            "Using environment: MiniGrid-Unlock-v0\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(f\"Minigrid version: {minigrid_version}\")\n",
        "\n",
        "env_name = \"MiniGrid-Unlock-v0\"\n",
        "print(f\"Using environment: {env_name}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "56jCSqqIy8ut"
      },
      "outputs": [],
      "source": [
        "class CustomCNN(BaseFeaturesExtractor):\n",
        "    def __init__(self, observation_space: gym.spaces.Box, features_dim: int = 64):\n",
        "        super(CustomCNN, self).__init__(observation_space, features_dim)\n",
        "        n_input_channels = observation_space.shape[0]\n",
        "        self.cnn = nn.Sequential(\n",
        "            nn.Conv2d(n_input_channels, 32, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Flatten(),\n",
        "        )\n",
        "\n",
        "        # Compute shape by doing one forward pass\n",
        "        with th.no_grad():\n",
        "            n_flatten = self.cnn(\n",
        "                th.as_tensor(observation_space.sample()[None]).float()\n",
        "            ).shape[1]\n",
        "\n",
        "        self.linear = nn.Sequential(nn.Linear(n_flatten, features_dim), nn.ReLU())\n",
        "\n",
        "    def forward(self, observations: th.Tensor) -> th.Tensor:\n",
        "        return self.linear(self.cnn(observations))\n",
        "\n",
        "def make_env():\n",
        "    def _init():\n",
        "        env = gym.make(env_name)\n",
        "        env = ImgObsWrapper(env)\n",
        "        return env\n",
        "    return _init\n",
        "\n",
        "policy_kwargs = dict(\n",
        "    features_extractor_class=CustomCNN,\n",
        "    features_extractor_kwargs=dict(features_dim=64),\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFfepqGAy8uu"
      },
      "source": [
        "# Experiment Description\n",
        "\n",
        "We ran experiments with three different vf_coef values: 0.5, 0.75, and 1.0. For each value, we ran three iterations to account for randomness in training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KYKdRLIsy8uu",
        "outputId": "7953573e-6625-44b9-f510-e3d0a5e09778"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Minigrid version: 2.3.1\n",
            "Using environment: MiniGrid-Unlock-v0\n",
            "Running experiment with vf_coef = 0.5, iteration 1\n",
            "Observation space: Box(0, 255, (3, 7, 7), uint8)\n",
            "Observation space shape: (3, 7, 7)\n",
            "Using cpu device\n",
            "Logging to ./ppo_minigrid_tensorboard/vf_coef_0.5/PPO_1\n",
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    fps             | 1721 |\n",
            "|    iterations      | 1    |\n",
            "|    time_elapsed    | 4    |\n",
            "|    total_timesteps | 8192 |\n",
            "-----------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 850         |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 19          |\n",
            "|    total_timesteps      | 16384       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.014854608 |\n",
            "|    clip_fraction        | 0.0938      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.94       |\n",
            "|    explained_variance   | -4.445804   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0324     |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.00738    |\n",
            "|    value_loss           | 2.7e-05     |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 730        |\n",
            "|    iterations           | 3          |\n",
            "|    time_elapsed         | 33         |\n",
            "|    total_timesteps      | 24576      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01893071 |\n",
            "|    clip_fraction        | 0.171      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -1.92      |\n",
            "|    explained_variance   | -6.3865824 |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.00221    |\n",
            "|    n_updates            | 20         |\n",
            "|    policy_gradient_loss | -0.00979   |\n",
            "|    value_loss           | 2.17e-05   |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 685        |\n",
            "|    iterations           | 4          |\n",
            "|    time_elapsed         | 47         |\n",
            "|    total_timesteps      | 32768      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00963488 |\n",
            "|    clip_fraction        | 0.103      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -1.91      |\n",
            "|    explained_variance   | -2.9308572 |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.0462     |\n",
            "|    n_updates            | 30         |\n",
            "|    policy_gradient_loss | -0.00766   |\n",
            "|    value_loss           | 1.79e-05   |\n",
            "----------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\marce\\anaconda3\\envs\\ppo_minigrid\\lib\\site-packages\\stable_baselines3\\common\\evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval num_timesteps=40000, episode_reward=0.00 +/- 0.00\n",
            "Episode length: 288.00 +/- 0.00\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 288          |\n",
            "|    mean_reward          | 0            |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 40000        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.010068912  |\n",
            "|    clip_fraction        | 0.0985       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.9         |\n",
            "|    explained_variance   | -0.013113022 |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.0221      |\n",
            "|    n_updates            | 40           |\n",
            "|    policy_gradient_loss | -0.00528     |\n",
            "|    value_loss           | 0.000773     |\n",
            "------------------------------------------\n",
            "New best mean reward!\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    fps             | 658   |\n",
            "|    iterations      | 5     |\n",
            "|    time_elapsed    | 62    |\n",
            "|    total_timesteps | 40960 |\n",
            "------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 650        |\n",
            "|    iterations           | 6          |\n",
            "|    time_elapsed         | 75         |\n",
            "|    total_timesteps      | 49152      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00919687 |\n",
            "|    clip_fraction        | 0.093      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -1.9       |\n",
            "|    explained_variance   | -4.615981  |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | -0.0395    |\n",
            "|    n_updates            | 50         |\n",
            "|    policy_gradient_loss | -0.00791   |\n",
            "|    value_loss           | 1.82e-05   |\n",
            "----------------------------------------\n",
            "--------------------------------------------\n",
            "| time/                   |                |\n",
            "|    fps                  | 642            |\n",
            "|    iterations           | 7              |\n",
            "|    time_elapsed         | 89             |\n",
            "|    total_timesteps      | 57344          |\n",
            "| train/                  |                |\n",
            "|    approx_kl            | 0.0063865446   |\n",
            "|    clip_fraction        | 0.0565         |\n",
            "|    clip_range           | 0.2            |\n",
            "|    entropy_loss         | -1.91          |\n",
            "|    explained_variance   | -0.00047028065 |\n",
            "|    learning_rate        | 0.0003         |\n",
            "|    loss                 | -0.0152        |\n",
            "|    n_updates            | 60             |\n",
            "|    policy_gradient_loss | -0.00533       |\n",
            "|    value_loss           | 0.000872       |\n",
            "--------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 639          |\n",
            "|    iterations           | 8            |\n",
            "|    time_elapsed         | 102          |\n",
            "|    total_timesteps      | 65536        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0126855355 |\n",
            "|    clip_fraction        | 0.141        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.9         |\n",
            "|    explained_variance   | -1.1516626   |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.0128      |\n",
            "|    n_updates            | 70           |\n",
            "|    policy_gradient_loss | -0.0125      |\n",
            "|    value_loss           | 2.36e-05     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 637         |\n",
            "|    iterations           | 9           |\n",
            "|    time_elapsed         | 115         |\n",
            "|    total_timesteps      | 73728       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012734222 |\n",
            "|    clip_fraction        | 0.0996      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.88       |\n",
            "|    explained_variance   | -1.093226   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0305     |\n",
            "|    n_updates            | 80          |\n",
            "|    policy_gradient_loss | -0.0111     |\n",
            "|    value_loss           | 8.07e-06    |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=80000, episode_reward=0.00 +/- 0.00\n",
            "Episode length: 288.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 288         |\n",
            "|    mean_reward          | 0           |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 80000       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011010705 |\n",
            "|    clip_fraction        | 0.128       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.85       |\n",
            "|    explained_variance   | 0.009067595 |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0301     |\n",
            "|    n_updates            | 90          |\n",
            "|    policy_gradient_loss | -0.00622    |\n",
            "|    value_loss           | 0.00107     |\n",
            "-----------------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    fps             | 631   |\n",
            "|    iterations      | 10    |\n",
            "|    time_elapsed    | 129   |\n",
            "|    total_timesteps | 81920 |\n",
            "------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 632         |\n",
            "|    iterations           | 11          |\n",
            "|    time_elapsed         | 142         |\n",
            "|    total_timesteps      | 90112       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012369841 |\n",
            "|    clip_fraction        | 0.15        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.83       |\n",
            "|    explained_variance   | 0.035381317 |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0215     |\n",
            "|    n_updates            | 100         |\n",
            "|    policy_gradient_loss | -0.0103     |\n",
            "|    value_loss           | 0.000756    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 629         |\n",
            "|    iterations           | 12          |\n",
            "|    time_elapsed         | 156         |\n",
            "|    total_timesteps      | 98304       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012160019 |\n",
            "|    clip_fraction        | 0.138       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.83       |\n",
            "|    explained_variance   | 0.06603235  |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0393     |\n",
            "|    n_updates            | 110         |\n",
            "|    policy_gradient_loss | -0.00896    |\n",
            "|    value_loss           | 0.00223     |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 627        |\n",
            "|    iterations           | 13         |\n",
            "|    time_elapsed         | 169        |\n",
            "|    total_timesteps      | 106496     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01145869 |\n",
            "|    clip_fraction        | 0.138      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -1.8       |\n",
            "|    explained_variance   | 0.08001351 |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | -0.0197    |\n",
            "|    n_updates            | 120        |\n",
            "|    policy_gradient_loss | -0.00828   |\n",
            "|    value_loss           | 0.00649    |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 627         |\n",
            "|    iterations           | 14          |\n",
            "|    time_elapsed         | 182         |\n",
            "|    total_timesteps      | 114688      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012272187 |\n",
            "|    clip_fraction        | 0.158       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.75       |\n",
            "|    explained_variance   | 0.12484151  |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0301     |\n",
            "|    n_updates            | 130         |\n",
            "|    policy_gradient_loss | -0.0125     |\n",
            "|    value_loss           | 0.00715     |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=120000, episode_reward=0.00 +/- 0.00\n",
            "Episode length: 288.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 288         |\n",
            "|    mean_reward          | 0           |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 120000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.014504956 |\n",
            "|    clip_fraction        | 0.174       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.7        |\n",
            "|    explained_variance   | 0.26709682  |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0394     |\n",
            "|    n_updates            | 140         |\n",
            "|    policy_gradient_loss | -0.0176     |\n",
            "|    value_loss           | 0.0111      |\n",
            "-----------------------------------------\n",
            "-------------------------------\n",
            "| time/              |        |\n",
            "|    fps             | 623    |\n",
            "|    iterations      | 15     |\n",
            "|    time_elapsed    | 197    |\n",
            "|    total_timesteps | 122880 |\n",
            "-------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 623         |\n",
            "|    iterations           | 16          |\n",
            "|    time_elapsed         | 210         |\n",
            "|    total_timesteps      | 131072      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013448175 |\n",
            "|    clip_fraction        | 0.198       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.66       |\n",
            "|    explained_variance   | 0.3672871   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0318     |\n",
            "|    n_updates            | 150         |\n",
            "|    policy_gradient_loss | -0.0201     |\n",
            "|    value_loss           | 0.0191      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 625         |\n",
            "|    iterations           | 17          |\n",
            "|    time_elapsed         | 222         |\n",
            "|    total_timesteps      | 139264      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.016207948 |\n",
            "|    clip_fraction        | 0.201       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.62       |\n",
            "|    explained_variance   | 0.47013485  |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.019      |\n",
            "|    n_updates            | 160         |\n",
            "|    policy_gradient_loss | -0.02       |\n",
            "|    value_loss           | 0.0204      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 625         |\n",
            "|    iterations           | 18          |\n",
            "|    time_elapsed         | 235         |\n",
            "|    total_timesteps      | 147456      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.018606966 |\n",
            "|    clip_fraction        | 0.218       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.55       |\n",
            "|    explained_variance   | 0.53106564  |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0431     |\n",
            "|    n_updates            | 170         |\n",
            "|    policy_gradient_loss | -0.0194     |\n",
            "|    value_loss           | 0.0172      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 625        |\n",
            "|    iterations           | 19         |\n",
            "|    time_elapsed         | 248        |\n",
            "|    total_timesteps      | 155648     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.02074191 |\n",
            "|    clip_fraction        | 0.264      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -1.47      |\n",
            "|    explained_variance   | 0.57523    |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | -0.0276    |\n",
            "|    n_updates            | 180        |\n",
            "|    policy_gradient_loss | -0.0254    |\n",
            "|    value_loss           | 0.0156     |\n",
            "----------------------------------------\n",
            "Eval num_timesteps=160000, episode_reward=0.58 +/- 0.48\n",
            "Episode length: 120.40 +/- 136.85\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 120         |\n",
            "|    mean_reward          | 0.584       |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 160000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.022122744 |\n",
            "|    clip_fraction        | 0.316       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.35       |\n",
            "|    explained_variance   | 0.56087065  |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.025      |\n",
            "|    n_updates            | 190         |\n",
            "|    policy_gradient_loss | -0.0294     |\n",
            "|    value_loss           | 0.0121      |\n",
            "-----------------------------------------\n",
            "New best mean reward!\n",
            "-------------------------------\n",
            "| time/              |        |\n",
            "|    fps             | 623    |\n",
            "|    iterations      | 20     |\n",
            "|    time_elapsed    | 262    |\n",
            "|    total_timesteps | 163840 |\n",
            "-------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 623         |\n",
            "|    iterations           | 21          |\n",
            "|    time_elapsed         | 275         |\n",
            "|    total_timesteps      | 172032      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.022337813 |\n",
            "|    clip_fraction        | 0.279       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.22       |\n",
            "|    explained_variance   | 0.64475954  |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0209     |\n",
            "|    n_updates            | 200         |\n",
            "|    policy_gradient_loss | -0.0236     |\n",
            "|    value_loss           | 0.00787     |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 623        |\n",
            "|    iterations           | 22         |\n",
            "|    time_elapsed         | 288        |\n",
            "|    total_timesteps      | 180224     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.02065419 |\n",
            "|    clip_fraction        | 0.223      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -1.04      |\n",
            "|    explained_variance   | 0.4110207  |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | -0.0156    |\n",
            "|    n_updates            | 210        |\n",
            "|    policy_gradient_loss | -0.0175    |\n",
            "|    value_loss           | 0.00415    |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 623         |\n",
            "|    iterations           | 23          |\n",
            "|    time_elapsed         | 302         |\n",
            "|    total_timesteps      | 188416      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.023576494 |\n",
            "|    clip_fraction        | 0.247       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.895      |\n",
            "|    explained_variance   | 0.5908971   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0473     |\n",
            "|    n_updates            | 220         |\n",
            "|    policy_gradient_loss | -0.02       |\n",
            "|    value_loss           | 0.00213     |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 623         |\n",
            "|    iterations           | 24          |\n",
            "|    time_elapsed         | 315         |\n",
            "|    total_timesteps      | 196608      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.028362064 |\n",
            "|    clip_fraction        | 0.226       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.725      |\n",
            "|    explained_variance   | 0.6405761   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.012      |\n",
            "|    n_updates            | 230         |\n",
            "|    policy_gradient_loss | -0.0192     |\n",
            "|    value_loss           | 0.00144     |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=200000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 11.60 +/- 1.50\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 11.6        |\n",
            "|    mean_reward          | 0.964       |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 200000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.044687107 |\n",
            "|    clip_fraction        | 0.25        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.598      |\n",
            "|    explained_variance   | 0.6525146   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0245     |\n",
            "|    n_updates            | 240         |\n",
            "|    policy_gradient_loss | -0.0211     |\n",
            "|    value_loss           | 0.00119     |\n",
            "-----------------------------------------\n",
            "New best mean reward!\n",
            "Stopping training because the mean reward 0.96  is above the threshold 0.95\n",
            "Running experiment with vf_coef = 0.5, iteration 2\n",
            "Observation space: Box(0, 255, (3, 7, 7), uint8)\n",
            "Observation space shape: (3, 7, 7)\n",
            "Using cpu device\n",
            "Logging to ./ppo_minigrid_tensorboard/vf_coef_0.5/PPO_2\n",
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    fps             | 1898 |\n",
            "|    iterations      | 1    |\n",
            "|    time_elapsed    | 4    |\n",
            "|    total_timesteps | 8192 |\n",
            "-----------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 938          |\n",
            "|    iterations           | 2            |\n",
            "|    time_elapsed         | 17           |\n",
            "|    total_timesteps      | 16384        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.009877909  |\n",
            "|    clip_fraction        | 0.0429       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.94        |\n",
            "|    explained_variance   | -0.015154004 |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.0296       |\n",
            "|    n_updates            | 10           |\n",
            "|    policy_gradient_loss | -0.00239     |\n",
            "|    value_loss           | 0.000872     |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 808        |\n",
            "|    iterations           | 3          |\n",
            "|    time_elapsed         | 30         |\n",
            "|    total_timesteps      | 24576      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01208818 |\n",
            "|    clip_fraction        | 0.0866     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -1.92      |\n",
            "|    explained_variance   | -1.6397262 |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | -0.0351    |\n",
            "|    n_updates            | 20         |\n",
            "|    policy_gradient_loss | -0.00679   |\n",
            "|    value_loss           | 3.27e-05   |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 752         |\n",
            "|    iterations           | 4           |\n",
            "|    time_elapsed         | 43          |\n",
            "|    total_timesteps      | 32768       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009418033 |\n",
            "|    clip_fraction        | 0.0789      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.92       |\n",
            "|    explained_variance   | 0.048725486 |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0194     |\n",
            "|    n_updates            | 30          |\n",
            "|    policy_gradient_loss | -0.00604    |\n",
            "|    value_loss           | 0.000359    |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=40000, episode_reward=0.00 +/- 0.00\n",
            "Episode length: 288.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 288         |\n",
            "|    mean_reward          | 0           |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 40000       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009550709 |\n",
            "|    clip_fraction        | 0.101       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.9        |\n",
            "|    explained_variance   | 0.023475826 |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0236     |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.00706    |\n",
            "|    value_loss           | 0.00062     |\n",
            "-----------------------------------------\n",
            "New best mean reward!\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    fps             | 713   |\n",
            "|    iterations      | 5     |\n",
            "|    time_elapsed    | 57    |\n",
            "|    total_timesteps | 40960 |\n",
            "------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 695          |\n",
            "|    iterations           | 6            |\n",
            "|    time_elapsed         | 70           |\n",
            "|    total_timesteps      | 49152        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.011020005  |\n",
            "|    clip_fraction        | 0.125        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.89        |\n",
            "|    explained_variance   | -0.013593912 |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.0167       |\n",
            "|    n_updates            | 50           |\n",
            "|    policy_gradient_loss | -0.0107      |\n",
            "|    value_loss           | 0.000622     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 682          |\n",
            "|    iterations           | 7            |\n",
            "|    time_elapsed         | 83           |\n",
            "|    total_timesteps      | 57344        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0113237295 |\n",
            "|    clip_fraction        | 0.132        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.88        |\n",
            "|    explained_variance   | 0.015155494  |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.0152      |\n",
            "|    n_updates            | 60           |\n",
            "|    policy_gradient_loss | -0.00745     |\n",
            "|    value_loss           | 0.00176      |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 674         |\n",
            "|    iterations           | 8           |\n",
            "|    time_elapsed         | 97          |\n",
            "|    total_timesteps      | 65536       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009661267 |\n",
            "|    clip_fraction        | 0.131       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.85       |\n",
            "|    explained_variance   | 0.043915153 |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0218     |\n",
            "|    n_updates            | 70          |\n",
            "|    policy_gradient_loss | -0.00767    |\n",
            "|    value_loss           | 0.00221     |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 669         |\n",
            "|    iterations           | 9           |\n",
            "|    time_elapsed         | 110         |\n",
            "|    total_timesteps      | 73728       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.014523943 |\n",
            "|    clip_fraction        | 0.131       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.83       |\n",
            "|    explained_variance   | 0.08103645  |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.021      |\n",
            "|    n_updates            | 80          |\n",
            "|    policy_gradient_loss | -0.012      |\n",
            "|    value_loss           | 0.000701    |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=80000, episode_reward=0.00 +/- 0.00\n",
            "Episode length: 288.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 288         |\n",
            "|    mean_reward          | 0           |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 80000       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012938226 |\n",
            "|    clip_fraction        | 0.168       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.8        |\n",
            "|    explained_variance   | 0.06913471  |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0125     |\n",
            "|    n_updates            | 90          |\n",
            "|    policy_gradient_loss | -0.0105     |\n",
            "|    value_loss           | 0.00521     |\n",
            "-----------------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    fps             | 658   |\n",
            "|    iterations      | 10    |\n",
            "|    time_elapsed    | 124   |\n",
            "|    total_timesteps | 81920 |\n",
            "------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 656         |\n",
            "|    iterations           | 11          |\n",
            "|    time_elapsed         | 137         |\n",
            "|    total_timesteps      | 90112       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013451556 |\n",
            "|    clip_fraction        | 0.16        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.78       |\n",
            "|    explained_variance   | 0.15474558  |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.026      |\n",
            "|    n_updates            | 100         |\n",
            "|    policy_gradient_loss | -0.016      |\n",
            "|    value_loss           | 0.009       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 653         |\n",
            "|    iterations           | 12          |\n",
            "|    time_elapsed         | 150         |\n",
            "|    total_timesteps      | 98304       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.014203802 |\n",
            "|    clip_fraction        | 0.161       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.77       |\n",
            "|    explained_variance   | 0.26780295  |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0271     |\n",
            "|    n_updates            | 110         |\n",
            "|    policy_gradient_loss | -0.0154     |\n",
            "|    value_loss           | 0.0125      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 651         |\n",
            "|    iterations           | 13          |\n",
            "|    time_elapsed         | 163         |\n",
            "|    total_timesteps      | 106496      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.014200252 |\n",
            "|    clip_fraction        | 0.173       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.72       |\n",
            "|    explained_variance   | 0.39603978  |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0268     |\n",
            "|    n_updates            | 120         |\n",
            "|    policy_gradient_loss | -0.0183     |\n",
            "|    value_loss           | 0.0215      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 650          |\n",
            "|    iterations           | 14           |\n",
            "|    time_elapsed         | 176          |\n",
            "|    total_timesteps      | 114688       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0154338945 |\n",
            "|    clip_fraction        | 0.197        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.66        |\n",
            "|    explained_variance   | 0.50785506   |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.00963     |\n",
            "|    n_updates            | 130          |\n",
            "|    policy_gradient_loss | -0.0214      |\n",
            "|    value_loss           | 0.0224       |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=120000, episode_reward=0.20 +/- 0.39\n",
            "Episode length: 231.40 +/- 113.20\n",
            "----------------------------------------\n",
            "| eval/                   |            |\n",
            "|    mean_ep_length       | 231        |\n",
            "|    mean_reward          | 0.197      |\n",
            "| time/                   |            |\n",
            "|    total_timesteps      | 120000     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01719804 |\n",
            "|    clip_fraction        | 0.234      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -1.57      |\n",
            "|    explained_variance   | 0.55343086 |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | -0.0329    |\n",
            "|    n_updates            | 140        |\n",
            "|    policy_gradient_loss | -0.0242    |\n",
            "|    value_loss           | 0.019      |\n",
            "----------------------------------------\n",
            "New best mean reward!\n",
            "-------------------------------\n",
            "| time/              |        |\n",
            "|    fps             | 644    |\n",
            "|    iterations      | 15     |\n",
            "|    time_elapsed    | 190    |\n",
            "|    total_timesteps | 122880 |\n",
            "-------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 643         |\n",
            "|    iterations           | 16          |\n",
            "|    time_elapsed         | 203         |\n",
            "|    total_timesteps      | 131072      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.017707717 |\n",
            "|    clip_fraction        | 0.243       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.47       |\n",
            "|    explained_variance   | 0.5862461   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.00699     |\n",
            "|    n_updates            | 150         |\n",
            "|    policy_gradient_loss | -0.0243     |\n",
            "|    value_loss           | 0.0144      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 643         |\n",
            "|    iterations           | 17          |\n",
            "|    time_elapsed         | 216         |\n",
            "|    total_timesteps      | 139264      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.021028753 |\n",
            "|    clip_fraction        | 0.275       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.36       |\n",
            "|    explained_variance   | 0.5493099   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0187     |\n",
            "|    n_updates            | 160         |\n",
            "|    policy_gradient_loss | -0.0243     |\n",
            "|    value_loss           | 0.00988     |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 642         |\n",
            "|    iterations           | 18          |\n",
            "|    time_elapsed         | 229         |\n",
            "|    total_timesteps      | 147456      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.023204476 |\n",
            "|    clip_fraction        | 0.295       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.19       |\n",
            "|    explained_variance   | 0.5618526   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0477     |\n",
            "|    n_updates            | 170         |\n",
            "|    policy_gradient_loss | -0.0247     |\n",
            "|    value_loss           | 0.00556     |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 641         |\n",
            "|    iterations           | 19          |\n",
            "|    time_elapsed         | 242         |\n",
            "|    total_timesteps      | 155648      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.030595254 |\n",
            "|    clip_fraction        | 0.291       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.06       |\n",
            "|    explained_variance   | 0.5356501   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.178       |\n",
            "|    n_updates            | 180         |\n",
            "|    policy_gradient_loss | -0.0208     |\n",
            "|    value_loss           | 0.00326     |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=160000, episode_reward=0.77 +/- 0.39\n",
            "Episode length: 66.20 +/- 110.95\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 66.2        |\n",
            "|    mean_reward          | 0.773       |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 160000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.028192017 |\n",
            "|    clip_fraction        | 0.293       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.969      |\n",
            "|    explained_variance   | 0.48985606  |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0206     |\n",
            "|    n_updates            | 190         |\n",
            "|    policy_gradient_loss | -0.0242     |\n",
            "|    value_loss           | 0.00259     |\n",
            "-----------------------------------------\n",
            "New best mean reward!\n",
            "-------------------------------\n",
            "| time/              |        |\n",
            "|    fps             | 637    |\n",
            "|    iterations      | 20     |\n",
            "|    time_elapsed    | 256    |\n",
            "|    total_timesteps | 163840 |\n",
            "-------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 636        |\n",
            "|    iterations           | 21         |\n",
            "|    time_elapsed         | 270        |\n",
            "|    total_timesteps      | 172032     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.03659207 |\n",
            "|    clip_fraction        | 0.304      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.845     |\n",
            "|    explained_variance   | 0.5590522  |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | -0.0236    |\n",
            "|    n_updates            | 200        |\n",
            "|    policy_gradient_loss | -0.0268    |\n",
            "|    value_loss           | 0.00212    |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 635         |\n",
            "|    iterations           | 22          |\n",
            "|    time_elapsed         | 283         |\n",
            "|    total_timesteps      | 180224      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.031758595 |\n",
            "|    clip_fraction        | 0.253       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.717      |\n",
            "|    explained_variance   | 0.62098765  |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.00935    |\n",
            "|    n_updates            | 210         |\n",
            "|    policy_gradient_loss | -0.0223     |\n",
            "|    value_loss           | 0.00173     |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 635         |\n",
            "|    iterations           | 23          |\n",
            "|    time_elapsed         | 296         |\n",
            "|    total_timesteps      | 188416      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.034602113 |\n",
            "|    clip_fraction        | 0.188       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.525      |\n",
            "|    explained_variance   | 0.5948531   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0427     |\n",
            "|    n_updates            | 220         |\n",
            "|    policy_gradient_loss | -0.0169     |\n",
            "|    value_loss           | 0.00118     |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 634         |\n",
            "|    iterations           | 24          |\n",
            "|    time_elapsed         | 309         |\n",
            "|    total_timesteps      | 196608      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.030082483 |\n",
            "|    clip_fraction        | 0.156       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.455      |\n",
            "|    explained_variance   | 0.62691253  |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0263     |\n",
            "|    n_updates            | 230         |\n",
            "|    policy_gradient_loss | -0.0137     |\n",
            "|    value_loss           | 0.00103     |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=200000, episode_reward=0.96 +/- 0.00\n",
            "Episode length: 12.00 +/- 1.26\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 12          |\n",
            "|    mean_reward          | 0.962       |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 200000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.024927141 |\n",
            "|    clip_fraction        | 0.125       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.318      |\n",
            "|    explained_variance   | 0.7168584   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.00657     |\n",
            "|    n_updates            | 240         |\n",
            "|    policy_gradient_loss | -0.00442    |\n",
            "|    value_loss           | 0.000692    |\n",
            "-----------------------------------------\n",
            "New best mean reward!\n",
            "Stopping training because the mean reward 0.96  is above the threshold 0.95\n",
            "Running experiment with vf_coef = 0.5, iteration 3\n",
            "Observation space: Box(0, 255, (3, 7, 7), uint8)\n",
            "Observation space shape: (3, 7, 7)\n",
            "Using cpu device\n",
            "Logging to ./ppo_minigrid_tensorboard/vf_coef_0.5/PPO_3\n",
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    fps             | 1920 |\n",
            "|    iterations      | 1    |\n",
            "|    time_elapsed    | 4    |\n",
            "|    total_timesteps | 8192 |\n",
            "-----------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 938        |\n",
            "|    iterations           | 2          |\n",
            "|    time_elapsed         | 17         |\n",
            "|    total_timesteps      | 16384      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01951309 |\n",
            "|    clip_fraction        | 0.13       |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -1.93      |\n",
            "|    explained_variance   | -6.047239  |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | -0.0218    |\n",
            "|    n_updates            | 10         |\n",
            "|    policy_gradient_loss | -0.012     |\n",
            "|    value_loss           | 1.99e-05   |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 802          |\n",
            "|    iterations           | 3            |\n",
            "|    time_elapsed         | 30           |\n",
            "|    total_timesteps      | 24576        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.009462698  |\n",
            "|    clip_fraction        | 0.0821       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.9         |\n",
            "|    explained_variance   | -0.009081721 |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.0237      |\n",
            "|    n_updates            | 20           |\n",
            "|    policy_gradient_loss | -0.00453     |\n",
            "|    value_loss           | 0.000252     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 751         |\n",
            "|    iterations           | 4           |\n",
            "|    time_elapsed         | 43          |\n",
            "|    total_timesteps      | 32768       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.01234496  |\n",
            "|    clip_fraction        | 0.127       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.88       |\n",
            "|    explained_variance   | -0.08632445 |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.00614     |\n",
            "|    n_updates            | 30          |\n",
            "|    policy_gradient_loss | -0.00675    |\n",
            "|    value_loss           | 0.000243    |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=40000, episode_reward=0.00 +/- 0.00\n",
            "Episode length: 288.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 288         |\n",
            "|    mean_reward          | 0           |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 40000       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010337835 |\n",
            "|    clip_fraction        | 0.117       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.87       |\n",
            "|    explained_variance   | -3.7694793  |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.018      |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.00738    |\n",
            "|    value_loss           | 1.78e-05    |\n",
            "-----------------------------------------\n",
            "New best mean reward!\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    fps             | 706   |\n",
            "|    iterations      | 5     |\n",
            "|    time_elapsed    | 57    |\n",
            "|    total_timesteps | 40960 |\n",
            "------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 694          |\n",
            "|    iterations           | 6            |\n",
            "|    time_elapsed         | 70           |\n",
            "|    total_timesteps      | 49152        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.011803687  |\n",
            "|    clip_fraction        | 0.123        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.85        |\n",
            "|    explained_variance   | -0.003055811 |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.0308      |\n",
            "|    n_updates            | 50           |\n",
            "|    policy_gradient_loss | -0.00439     |\n",
            "|    value_loss           | 0.000563     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 682          |\n",
            "|    iterations           | 7            |\n",
            "|    time_elapsed         | 84           |\n",
            "|    total_timesteps      | 57344        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0126126185 |\n",
            "|    clip_fraction        | 0.12         |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.85        |\n",
            "|    explained_variance   | -0.008006692 |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.0304      |\n",
            "|    n_updates            | 60           |\n",
            "|    policy_gradient_loss | -0.00817     |\n",
            "|    value_loss           | 0.000383     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 673         |\n",
            "|    iterations           | 8           |\n",
            "|    time_elapsed         | 97          |\n",
            "|    total_timesteps      | 65536       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.019132018 |\n",
            "|    clip_fraction        | 0.18        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.84       |\n",
            "|    explained_variance   | -2.7812889  |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0123     |\n",
            "|    n_updates            | 70          |\n",
            "|    policy_gradient_loss | -0.0136     |\n",
            "|    value_loss           | 2.64e-05    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 666          |\n",
            "|    iterations           | 9            |\n",
            "|    time_elapsed         | 110          |\n",
            "|    total_timesteps      | 73728        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.01161051   |\n",
            "|    clip_fraction        | 0.13         |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.82        |\n",
            "|    explained_variance   | -0.008134007 |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.0274      |\n",
            "|    n_updates            | 80           |\n",
            "|    policy_gradient_loss | -0.00782     |\n",
            "|    value_loss           | 0.000554     |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=80000, episode_reward=0.00 +/- 0.00\n",
            "Episode length: 288.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 288         |\n",
            "|    mean_reward          | 0           |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 80000       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011469277 |\n",
            "|    clip_fraction        | 0.162       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.8        |\n",
            "|    explained_variance   | -1.0502002  |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.00668    |\n",
            "|    n_updates            | 90          |\n",
            "|    policy_gradient_loss | -0.00975    |\n",
            "|    value_loss           | 6.51e-05    |\n",
            "-----------------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    fps             | 655   |\n",
            "|    iterations      | 10    |\n",
            "|    time_elapsed    | 125   |\n",
            "|    total_timesteps | 81920 |\n",
            "------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 652         |\n",
            "|    iterations           | 11          |\n",
            "|    time_elapsed         | 138         |\n",
            "|    total_timesteps      | 90112       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009959359 |\n",
            "|    clip_fraction        | 0.135       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.77       |\n",
            "|    explained_variance   | 0.017081857 |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.00772    |\n",
            "|    n_updates            | 100         |\n",
            "|    policy_gradient_loss | -0.00497    |\n",
            "|    value_loss           | 0.00222     |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 651          |\n",
            "|    iterations           | 12           |\n",
            "|    time_elapsed         | 150          |\n",
            "|    total_timesteps      | 98304        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.010936449  |\n",
            "|    clip_fraction        | 0.152        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.7         |\n",
            "|    explained_variance   | 0.0087791085 |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.0171       |\n",
            "|    n_updates            | 110          |\n",
            "|    policy_gradient_loss | -0.00613     |\n",
            "|    value_loss           | 0.0014       |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 649         |\n",
            "|    iterations           | 13          |\n",
            "|    time_elapsed         | 164         |\n",
            "|    total_timesteps      | 106496      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.014414696 |\n",
            "|    clip_fraction        | 0.173       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.65       |\n",
            "|    explained_variance   | -0.01896441 |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.0179      |\n",
            "|    n_updates            | 120         |\n",
            "|    policy_gradient_loss | -0.00895    |\n",
            "|    value_loss           | 0.00131     |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 647         |\n",
            "|    iterations           | 14          |\n",
            "|    time_elapsed         | 177         |\n",
            "|    total_timesteps      | 114688      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011744792 |\n",
            "|    clip_fraction        | 0.126       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.59       |\n",
            "|    explained_variance   | 0.037742138 |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.00546    |\n",
            "|    n_updates            | 130         |\n",
            "|    policy_gradient_loss | -0.00526    |\n",
            "|    value_loss           | 0.00285     |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=120000, episode_reward=0.00 +/- 0.00\n",
            "Episode length: 288.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 288         |\n",
            "|    mean_reward          | 0           |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 120000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009150775 |\n",
            "|    clip_fraction        | 0.111       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.55       |\n",
            "|    explained_variance   | 0.087643385 |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0469     |\n",
            "|    n_updates            | 140         |\n",
            "|    policy_gradient_loss | -0.00636    |\n",
            "|    value_loss           | 0.00361     |\n",
            "-----------------------------------------\n",
            "-------------------------------\n",
            "| time/              |        |\n",
            "|    fps             | 641    |\n",
            "|    iterations      | 15     |\n",
            "|    time_elapsed    | 191    |\n",
            "|    total_timesteps | 122880 |\n",
            "-------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 640         |\n",
            "|    iterations           | 16          |\n",
            "|    time_elapsed         | 204         |\n",
            "|    total_timesteps      | 131072      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010548447 |\n",
            "|    clip_fraction        | 0.124       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.54       |\n",
            "|    explained_variance   | 0.17928684  |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0148     |\n",
            "|    n_updates            | 150         |\n",
            "|    policy_gradient_loss | -0.00604    |\n",
            "|    value_loss           | 0.0026      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 640         |\n",
            "|    iterations           | 17          |\n",
            "|    time_elapsed         | 217         |\n",
            "|    total_timesteps      | 139264      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008944553 |\n",
            "|    clip_fraction        | 0.105       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.54       |\n",
            "|    explained_variance   | 0.1876989   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.00828     |\n",
            "|    n_updates            | 160         |\n",
            "|    policy_gradient_loss | -0.00639    |\n",
            "|    value_loss           | 0.00592     |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 640         |\n",
            "|    iterations           | 18          |\n",
            "|    time_elapsed         | 230         |\n",
            "|    total_timesteps      | 147456      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011369922 |\n",
            "|    clip_fraction        | 0.146       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.51       |\n",
            "|    explained_variance   | 0.32900393  |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.0197      |\n",
            "|    n_updates            | 170         |\n",
            "|    policy_gradient_loss | -0.0101     |\n",
            "|    value_loss           | 0.00724     |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 639         |\n",
            "|    iterations           | 19          |\n",
            "|    time_elapsed         | 243         |\n",
            "|    total_timesteps      | 155648      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013823751 |\n",
            "|    clip_fraction        | 0.165       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.4        |\n",
            "|    explained_variance   | 0.44555777  |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.000536   |\n",
            "|    n_updates            | 180         |\n",
            "|    policy_gradient_loss | -0.0127     |\n",
            "|    value_loss           | 0.0108      |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=160000, episode_reward=0.00 +/- 0.00\n",
            "Episode length: 288.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 288         |\n",
            "|    mean_reward          | 0           |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 160000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011574266 |\n",
            "|    clip_fraction        | 0.136       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.37       |\n",
            "|    explained_variance   | 0.47481096  |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.00168     |\n",
            "|    n_updates            | 190         |\n",
            "|    policy_gradient_loss | -0.0122     |\n",
            "|    value_loss           | 0.0137      |\n",
            "-----------------------------------------\n",
            "-------------------------------\n",
            "| time/              |        |\n",
            "|    fps             | 635    |\n",
            "|    iterations      | 20     |\n",
            "|    time_elapsed    | 257    |\n",
            "|    total_timesteps | 163840 |\n",
            "-------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 634         |\n",
            "|    iterations           | 21          |\n",
            "|    time_elapsed         | 271         |\n",
            "|    total_timesteps      | 172032      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.014510166 |\n",
            "|    clip_fraction        | 0.176       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.37       |\n",
            "|    explained_variance   | 0.5024861   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.0213      |\n",
            "|    n_updates            | 200         |\n",
            "|    policy_gradient_loss | -0.0156     |\n",
            "|    value_loss           | 0.0166      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 634         |\n",
            "|    iterations           | 22          |\n",
            "|    time_elapsed         | 284         |\n",
            "|    total_timesteps      | 180224      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.015884422 |\n",
            "|    clip_fraction        | 0.18        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.36       |\n",
            "|    explained_variance   | 0.5890301   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0311     |\n",
            "|    n_updates            | 210         |\n",
            "|    policy_gradient_loss | -0.0164     |\n",
            "|    value_loss           | 0.0148      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 633         |\n",
            "|    iterations           | 23          |\n",
            "|    time_elapsed         | 297         |\n",
            "|    total_timesteps      | 188416      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.017977744 |\n",
            "|    clip_fraction        | 0.236       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.28       |\n",
            "|    explained_variance   | 0.59732044  |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.00496    |\n",
            "|    n_updates            | 220         |\n",
            "|    policy_gradient_loss | -0.0213     |\n",
            "|    value_loss           | 0.014       |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 631        |\n",
            "|    iterations           | 24         |\n",
            "|    time_elapsed         | 311        |\n",
            "|    total_timesteps      | 196608     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01908258 |\n",
            "|    clip_fraction        | 0.244      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -1.19      |\n",
            "|    explained_variance   | 0.5800321  |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | -0.022     |\n",
            "|    n_updates            | 230        |\n",
            "|    policy_gradient_loss | -0.022     |\n",
            "|    value_loss           | 0.0112     |\n",
            "----------------------------------------\n",
            "Eval num_timesteps=200000, episode_reward=0.19 +/- 0.39\n",
            "Episode length: 232.20 +/- 111.60\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 232         |\n",
            "|    mean_reward          | 0.194       |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 200000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.017654486 |\n",
            "|    clip_fraction        | 0.219       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.12       |\n",
            "|    explained_variance   | 0.5825835   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0135     |\n",
            "|    n_updates            | 240         |\n",
            "|    policy_gradient_loss | -0.0231     |\n",
            "|    value_loss           | 0.0087      |\n",
            "-----------------------------------------\n",
            "New best mean reward!\n",
            "-------------------------------\n",
            "| time/              |        |\n",
            "|    fps             | 628    |\n",
            "|    iterations      | 25     |\n",
            "|    time_elapsed    | 325    |\n",
            "|    total_timesteps | 204800 |\n",
            "-------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 628         |\n",
            "|    iterations           | 26          |\n",
            "|    time_elapsed         | 338         |\n",
            "|    total_timesteps      | 212992      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.017300405 |\n",
            "|    clip_fraction        | 0.204       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1          |\n",
            "|    explained_variance   | 0.60637164  |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0143     |\n",
            "|    n_updates            | 250         |\n",
            "|    policy_gradient_loss | -0.0197     |\n",
            "|    value_loss           | 0.00567     |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 628         |\n",
            "|    iterations           | 27          |\n",
            "|    time_elapsed         | 352         |\n",
            "|    total_timesteps      | 221184      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.018267857 |\n",
            "|    clip_fraction        | 0.213       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.914      |\n",
            "|    explained_variance   | 0.6025449   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.021      |\n",
            "|    n_updates            | 260         |\n",
            "|    policy_gradient_loss | -0.0198     |\n",
            "|    value_loss           | 0.00383     |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 628         |\n",
            "|    iterations           | 28          |\n",
            "|    time_elapsed         | 365         |\n",
            "|    total_timesteps      | 229376      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.015490253 |\n",
            "|    clip_fraction        | 0.198       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.818      |\n",
            "|    explained_variance   | 0.64873916  |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0387     |\n",
            "|    n_updates            | 270         |\n",
            "|    policy_gradient_loss | -0.0203     |\n",
            "|    value_loss           | 0.00256     |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 628         |\n",
            "|    iterations           | 29          |\n",
            "|    time_elapsed         | 378         |\n",
            "|    total_timesteps      | 237568      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.015545496 |\n",
            "|    clip_fraction        | 0.157       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.672      |\n",
            "|    explained_variance   | 0.62934816  |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0134     |\n",
            "|    n_updates            | 280         |\n",
            "|    policy_gradient_loss | -0.0157     |\n",
            "|    value_loss           | 0.0021      |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=240000, episode_reward=0.75 +/- 0.37\n",
            "Episode length: 74.20 +/- 106.94\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 74.2        |\n",
            "|    mean_reward          | 0.748       |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 240000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.019855164 |\n",
            "|    clip_fraction        | 0.154       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.542      |\n",
            "|    explained_variance   | 0.67022777  |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0287     |\n",
            "|    n_updates            | 290         |\n",
            "|    policy_gradient_loss | -0.0156     |\n",
            "|    value_loss           | 0.00171     |\n",
            "-----------------------------------------\n",
            "New best mean reward!\n",
            "-------------------------------\n",
            "| time/              |        |\n",
            "|    fps             | 627    |\n",
            "|    iterations      | 30     |\n",
            "|    time_elapsed    | 391    |\n",
            "|    total_timesteps | 245760 |\n",
            "-------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 627         |\n",
            "|    iterations           | 31          |\n",
            "|    time_elapsed         | 404         |\n",
            "|    total_timesteps      | 253952      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.015448134 |\n",
            "|    clip_fraction        | 0.124       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.473      |\n",
            "|    explained_variance   | 0.6669171   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0275     |\n",
            "|    n_updates            | 300         |\n",
            "|    policy_gradient_loss | -0.0135     |\n",
            "|    value_loss           | 0.00153     |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 627        |\n",
            "|    iterations           | 32         |\n",
            "|    time_elapsed         | 417        |\n",
            "|    total_timesteps      | 262144     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01361927 |\n",
            "|    clip_fraction        | 0.117      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.425     |\n",
            "|    explained_variance   | 0.670097   |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | -0.0304    |\n",
            "|    n_updates            | 310        |\n",
            "|    policy_gradient_loss | -0.00993   |\n",
            "|    value_loss           | 0.00131    |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 626         |\n",
            "|    iterations           | 33          |\n",
            "|    time_elapsed         | 431         |\n",
            "|    total_timesteps      | 270336      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.019643236 |\n",
            "|    clip_fraction        | 0.118       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.374      |\n",
            "|    explained_variance   | 0.6702181   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.00921     |\n",
            "|    n_updates            | 320         |\n",
            "|    policy_gradient_loss | -0.0111     |\n",
            "|    value_loss           | 0.0013      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 626         |\n",
            "|    iterations           | 34          |\n",
            "|    time_elapsed         | 444         |\n",
            "|    total_timesteps      | 278528      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.021129215 |\n",
            "|    clip_fraction        | 0.129       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.344      |\n",
            "|    explained_variance   | 0.6788702   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0137     |\n",
            "|    n_updates            | 330         |\n",
            "|    policy_gradient_loss | -0.011      |\n",
            "|    value_loss           | 0.00118     |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=280000, episode_reward=0.95 +/- 0.01\n",
            "Episode length: 14.80 +/- 4.53\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 14.8        |\n",
            "|    mean_reward          | 0.954       |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 280000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.029863436 |\n",
            "|    clip_fraction        | 0.111       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.32       |\n",
            "|    explained_variance   | 0.65480244  |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.00259    |\n",
            "|    n_updates            | 340         |\n",
            "|    policy_gradient_loss | -0.00986    |\n",
            "|    value_loss           | 0.00119     |\n",
            "-----------------------------------------\n",
            "New best mean reward!\n",
            "Stopping training because the mean reward 0.95  is above the threshold 0.95\n",
            "Running experiment with vf_coef = 0.75, iteration 1\n",
            "Observation space: Box(0, 255, (3, 7, 7), uint8)\n",
            "Observation space shape: (3, 7, 7)\n",
            "Using cpu device\n",
            "Logging to ./ppo_minigrid_tensorboard/vf_coef_0.75/PPO_1\n",
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    fps             | 1865 |\n",
            "|    iterations      | 1    |\n",
            "|    time_elapsed    | 4    |\n",
            "|    total_timesteps | 8192 |\n",
            "-----------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 963         |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 17          |\n",
            "|    total_timesteps      | 16384       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011709108 |\n",
            "|    clip_fraction        | 0.043       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.94       |\n",
            "|    explained_variance   | -0.13196576 |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0124     |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.00337    |\n",
            "|    value_loss           | 4.91e-05    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 814         |\n",
            "|    iterations           | 3           |\n",
            "|    time_elapsed         | 30          |\n",
            "|    total_timesteps      | 24576       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010065971 |\n",
            "|    clip_fraction        | 0.0775      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.93       |\n",
            "|    explained_variance   | -0.99535835 |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0214     |\n",
            "|    n_updates            | 20          |\n",
            "|    policy_gradient_loss | -0.00777    |\n",
            "|    value_loss           | 1.48e-05    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 758          |\n",
            "|    iterations           | 4            |\n",
            "|    time_elapsed         | 43           |\n",
            "|    total_timesteps      | 32768        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.010083442  |\n",
            "|    clip_fraction        | 0.111        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.91        |\n",
            "|    explained_variance   | -0.025584936 |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.0305      |\n",
            "|    n_updates            | 30           |\n",
            "|    policy_gradient_loss | -0.00555     |\n",
            "|    value_loss           | 0.000761     |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=40000, episode_reward=0.00 +/- 0.00\n",
            "Episode length: 288.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 288         |\n",
            "|    mean_reward          | 0           |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 40000       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.01230168  |\n",
            "|    clip_fraction        | 0.142       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.89       |\n",
            "|    explained_variance   | 0.018059492 |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0323     |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.00759    |\n",
            "|    value_loss           | 0.00125     |\n",
            "-----------------------------------------\n",
            "New best mean reward!\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    fps             | 709   |\n",
            "|    iterations      | 5     |\n",
            "|    time_elapsed    | 57    |\n",
            "|    total_timesteps | 40960 |\n",
            "------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 695         |\n",
            "|    iterations           | 6           |\n",
            "|    time_elapsed         | 70          |\n",
            "|    total_timesteps      | 49152       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011998599 |\n",
            "|    clip_fraction        | 0.14        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.87       |\n",
            "|    explained_variance   | -0.074139   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.00441    |\n",
            "|    n_updates            | 50          |\n",
            "|    policy_gradient_loss | -0.0114     |\n",
            "|    value_loss           | 0.000278    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 687         |\n",
            "|    iterations           | 7           |\n",
            "|    time_elapsed         | 83          |\n",
            "|    total_timesteps      | 57344       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010798855 |\n",
            "|    clip_fraction        | 0.141       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.85       |\n",
            "|    explained_variance   | 0.027289867 |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0258     |\n",
            "|    n_updates            | 60          |\n",
            "|    policy_gradient_loss | -0.00748    |\n",
            "|    value_loss           | 0.00265     |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 679         |\n",
            "|    iterations           | 8           |\n",
            "|    time_elapsed         | 96          |\n",
            "|    total_timesteps      | 65536       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011350434 |\n",
            "|    clip_fraction        | 0.144       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.84       |\n",
            "|    explained_variance   | 0.04819095  |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0179     |\n",
            "|    n_updates            | 70          |\n",
            "|    policy_gradient_loss | -0.00913    |\n",
            "|    value_loss           | 0.00319     |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 673         |\n",
            "|    iterations           | 9           |\n",
            "|    time_elapsed         | 109         |\n",
            "|    total_timesteps      | 73728       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010325847 |\n",
            "|    clip_fraction        | 0.142       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.82       |\n",
            "|    explained_variance   | 0.079841256 |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.00258     |\n",
            "|    n_updates            | 80          |\n",
            "|    policy_gradient_loss | -0.00796    |\n",
            "|    value_loss           | 0.00214     |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=80000, episode_reward=0.00 +/- 0.00\n",
            "Episode length: 288.00 +/- 0.00\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 288          |\n",
            "|    mean_reward          | 0            |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 80000        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0117292665 |\n",
            "|    clip_fraction        | 0.151        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.79        |\n",
            "|    explained_variance   | 0.10730016   |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.0052       |\n",
            "|    n_updates            | 90           |\n",
            "|    policy_gradient_loss | -0.00832     |\n",
            "|    value_loss           | 0.00271      |\n",
            "------------------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    fps             | 661   |\n",
            "|    iterations      | 10    |\n",
            "|    time_elapsed    | 123   |\n",
            "|    total_timesteps | 81920 |\n",
            "------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 658         |\n",
            "|    iterations           | 11          |\n",
            "|    time_elapsed         | 136         |\n",
            "|    total_timesteps      | 90112       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011748714 |\n",
            "|    clip_fraction        | 0.142       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.77       |\n",
            "|    explained_variance   | 0.12958473  |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.00555     |\n",
            "|    n_updates            | 100         |\n",
            "|    policy_gradient_loss | -0.0123     |\n",
            "|    value_loss           | 0.0078      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 655        |\n",
            "|    iterations           | 12         |\n",
            "|    time_elapsed         | 149        |\n",
            "|    total_timesteps      | 98304      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01121008 |\n",
            "|    clip_fraction        | 0.131      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -1.75      |\n",
            "|    explained_variance   | 0.24701744 |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.0207     |\n",
            "|    n_updates            | 110        |\n",
            "|    policy_gradient_loss | -0.0126    |\n",
            "|    value_loss           | 0.0101     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 655         |\n",
            "|    iterations           | 13          |\n",
            "|    time_elapsed         | 162         |\n",
            "|    total_timesteps      | 106496      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012420941 |\n",
            "|    clip_fraction        | 0.158       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.66       |\n",
            "|    explained_variance   | 0.3737821   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.0126      |\n",
            "|    n_updates            | 120         |\n",
            "|    policy_gradient_loss | -0.0156     |\n",
            "|    value_loss           | 0.0181      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 653         |\n",
            "|    iterations           | 14          |\n",
            "|    time_elapsed         | 175         |\n",
            "|    total_timesteps      | 114688      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.016903266 |\n",
            "|    clip_fraction        | 0.187       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.61       |\n",
            "|    explained_variance   | 0.4434917   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0326     |\n",
            "|    n_updates            | 130         |\n",
            "|    policy_gradient_loss | -0.0215     |\n",
            "|    value_loss           | 0.0225      |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=120000, episode_reward=0.58 +/- 0.47\n",
            "Episode length: 121.60 +/- 135.88\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 122         |\n",
            "|    mean_reward          | 0.58        |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 120000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.017619826 |\n",
            "|    clip_fraction        | 0.214       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.54       |\n",
            "|    explained_variance   | 0.5226059   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0256     |\n",
            "|    n_updates            | 140         |\n",
            "|    policy_gradient_loss | -0.0214     |\n",
            "|    value_loss           | 0.0224      |\n",
            "-----------------------------------------\n",
            "New best mean reward!\n",
            "-------------------------------\n",
            "| time/              |        |\n",
            "|    fps             | 649    |\n",
            "|    iterations      | 15     |\n",
            "|    time_elapsed    | 189    |\n",
            "|    total_timesteps | 122880 |\n",
            "-------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 646         |\n",
            "|    iterations           | 16          |\n",
            "|    time_elapsed         | 202         |\n",
            "|    total_timesteps      | 131072      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.019332025 |\n",
            "|    clip_fraction        | 0.231       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.42       |\n",
            "|    explained_variance   | 0.5623341   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0118     |\n",
            "|    n_updates            | 150         |\n",
            "|    policy_gradient_loss | -0.0234     |\n",
            "|    value_loss           | 0.0163      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 644         |\n",
            "|    iterations           | 17          |\n",
            "|    time_elapsed         | 216         |\n",
            "|    total_timesteps      | 139264      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.022377644 |\n",
            "|    clip_fraction        | 0.257       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.28       |\n",
            "|    explained_variance   | 0.54308265  |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.00923    |\n",
            "|    n_updates            | 160         |\n",
            "|    policy_gradient_loss | -0.0214     |\n",
            "|    value_loss           | 0.00965     |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 642        |\n",
            "|    iterations           | 18         |\n",
            "|    time_elapsed         | 229        |\n",
            "|    total_timesteps      | 147456     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01949243 |\n",
            "|    clip_fraction        | 0.228      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -1.08      |\n",
            "|    explained_variance   | 0.51451373 |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | -0.0222    |\n",
            "|    n_updates            | 170        |\n",
            "|    policy_gradient_loss | -0.0191    |\n",
            "|    value_loss           | 0.00495    |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 642        |\n",
            "|    iterations           | 19         |\n",
            "|    time_elapsed         | 242        |\n",
            "|    total_timesteps      | 155648     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.02246105 |\n",
            "|    clip_fraction        | 0.259      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.941     |\n",
            "|    explained_variance   | 0.64691216 |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | -0.0113    |\n",
            "|    n_updates            | 180        |\n",
            "|    policy_gradient_loss | -0.024     |\n",
            "|    value_loss           | 0.00318    |\n",
            "----------------------------------------\n",
            "Eval num_timesteps=160000, episode_reward=0.78 +/- 0.39\n",
            "Episode length: 64.80 +/- 111.62\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 64.8        |\n",
            "|    mean_reward          | 0.777       |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 160000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.032162964 |\n",
            "|    clip_fraction        | 0.233       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.789      |\n",
            "|    explained_variance   | 0.60581166  |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.012      |\n",
            "|    n_updates            | 190         |\n",
            "|    policy_gradient_loss | -0.015      |\n",
            "|    value_loss           | 0.00189     |\n",
            "-----------------------------------------\n",
            "New best mean reward!\n",
            "-------------------------------\n",
            "| time/              |        |\n",
            "|    fps             | 639    |\n",
            "|    iterations      | 20     |\n",
            "|    time_elapsed    | 256    |\n",
            "|    total_timesteps | 163840 |\n",
            "-------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 638         |\n",
            "|    iterations           | 21          |\n",
            "|    time_elapsed         | 269         |\n",
            "|    total_timesteps      | 172032      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.027813017 |\n",
            "|    clip_fraction        | 0.255       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.693      |\n",
            "|    explained_variance   | 0.57943183  |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.00319     |\n",
            "|    n_updates            | 200         |\n",
            "|    policy_gradient_loss | -0.0178     |\n",
            "|    value_loss           | 0.00164     |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 637         |\n",
            "|    iterations           | 22          |\n",
            "|    time_elapsed         | 282         |\n",
            "|    total_timesteps      | 180224      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.043320313 |\n",
            "|    clip_fraction        | 0.227       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.56       |\n",
            "|    explained_variance   | 0.67147875  |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0348     |\n",
            "|    n_updates            | 210         |\n",
            "|    policy_gradient_loss | -0.0175     |\n",
            "|    value_loss           | 0.00111     |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 636         |\n",
            "|    iterations           | 23          |\n",
            "|    time_elapsed         | 296         |\n",
            "|    total_timesteps      | 188416      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.033970498 |\n",
            "|    clip_fraction        | 0.173       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.441      |\n",
            "|    explained_variance   | 0.57903063  |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0382     |\n",
            "|    n_updates            | 220         |\n",
            "|    policy_gradient_loss | -0.00966    |\n",
            "|    value_loss           | 0.0011      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 635         |\n",
            "|    iterations           | 24          |\n",
            "|    time_elapsed         | 309         |\n",
            "|    total_timesteps      | 196608      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.030418076 |\n",
            "|    clip_fraction        | 0.129       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.339      |\n",
            "|    explained_variance   | 0.6719307   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0222     |\n",
            "|    n_updates            | 230         |\n",
            "|    policy_gradient_loss | -0.00491    |\n",
            "|    value_loss           | 0.000918    |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=200000, episode_reward=0.78 +/- 0.39\n",
            "Episode length: 65.40 +/- 111.31\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 65.4        |\n",
            "|    mean_reward          | 0.776       |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 200000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.033895634 |\n",
            "|    clip_fraction        | 0.14        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.297      |\n",
            "|    explained_variance   | 0.6455873   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.00582    |\n",
            "|    n_updates            | 240         |\n",
            "|    policy_gradient_loss | -0.0111     |\n",
            "|    value_loss           | 0.00122     |\n",
            "-----------------------------------------\n",
            "-------------------------------\n",
            "| time/              |        |\n",
            "|    fps             | 634    |\n",
            "|    iterations      | 25     |\n",
            "|    time_elapsed    | 322    |\n",
            "|    total_timesteps | 204800 |\n",
            "-------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 634         |\n",
            "|    iterations           | 26          |\n",
            "|    time_elapsed         | 335         |\n",
            "|    total_timesteps      | 212992      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.034055427 |\n",
            "|    clip_fraction        | 0.11        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.22       |\n",
            "|    explained_variance   | 0.6960456   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0201     |\n",
            "|    n_updates            | 250         |\n",
            "|    policy_gradient_loss | -0.0041     |\n",
            "|    value_loss           | 0.000763    |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 633        |\n",
            "|    iterations           | 27         |\n",
            "|    time_elapsed         | 349        |\n",
            "|    total_timesteps      | 221184     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.06042341 |\n",
            "|    clip_fraction        | 0.21       |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.32      |\n",
            "|    explained_variance   | 0.37448817 |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | -0.0421    |\n",
            "|    n_updates            | 260        |\n",
            "|    policy_gradient_loss | -0.0102    |\n",
            "|    value_loss           | 0.00147    |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 633        |\n",
            "|    iterations           | 28         |\n",
            "|    time_elapsed         | 362        |\n",
            "|    total_timesteps      | 229376     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.05329359 |\n",
            "|    clip_fraction        | 0.138      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.201     |\n",
            "|    explained_variance   | 0.650732   |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | -0.0256    |\n",
            "|    n_updates            | 270        |\n",
            "|    policy_gradient_loss | -0.00938   |\n",
            "|    value_loss           | 0.000725   |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 632         |\n",
            "|    iterations           | 29          |\n",
            "|    time_elapsed         | 375         |\n",
            "|    total_timesteps      | 237568      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.034238912 |\n",
            "|    clip_fraction        | 0.137       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.203      |\n",
            "|    explained_variance   | 0.71838516  |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0331     |\n",
            "|    n_updates            | 280         |\n",
            "|    policy_gradient_loss | -0.00979    |\n",
            "|    value_loss           | 0.000525    |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=240000, episode_reward=0.97 +/- 0.01\n",
            "Episode length: 10.00 +/- 2.61\n",
            "----------------------------------------\n",
            "| eval/                   |            |\n",
            "|    mean_ep_length       | 10         |\n",
            "|    mean_reward          | 0.969      |\n",
            "| time/                   |            |\n",
            "|    total_timesteps      | 240000     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.04024041 |\n",
            "|    clip_fraction        | 0.175      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.187     |\n",
            "|    explained_variance   | 0.606291   |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.00368    |\n",
            "|    n_updates            | 290        |\n",
            "|    policy_gradient_loss | -0.0169    |\n",
            "|    value_loss           | 0.00087    |\n",
            "----------------------------------------\n",
            "New best mean reward!\n",
            "Stopping training because the mean reward 0.97  is above the threshold 0.95\n",
            "Running experiment with vf_coef = 0.75, iteration 2\n",
            "Observation space: Box(0, 255, (3, 7, 7), uint8)\n",
            "Observation space shape: (3, 7, 7)\n",
            "Using cpu device\n",
            "Logging to ./ppo_minigrid_tensorboard/vf_coef_0.75/PPO_2\n",
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    fps             | 1797 |\n",
            "|    iterations      | 1    |\n",
            "|    time_elapsed    | 4    |\n",
            "|    total_timesteps | 8192 |\n",
            "-----------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 937         |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 17          |\n",
            "|    total_timesteps      | 16384       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009558599 |\n",
            "|    clip_fraction        | 0.0685      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.94       |\n",
            "|    explained_variance   | -0.08137989 |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0177     |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.00484    |\n",
            "|    value_loss           | 0.000249    |\n",
            "-----------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 804           |\n",
            "|    iterations           | 3             |\n",
            "|    time_elapsed         | 30            |\n",
            "|    total_timesteps      | 24576         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.012511275   |\n",
            "|    clip_fraction        | 0.116         |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -1.93         |\n",
            "|    explained_variance   | 0.00035136938 |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | -0.0379       |\n",
            "|    n_updates            | 20            |\n",
            "|    policy_gradient_loss | -0.00753      |\n",
            "|    value_loss           | 0.000815      |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 751          |\n",
            "|    iterations           | 4            |\n",
            "|    time_elapsed         | 43           |\n",
            "|    total_timesteps      | 32768        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.009914094  |\n",
            "|    clip_fraction        | 0.104        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.9         |\n",
            "|    explained_variance   | 0.0028164983 |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.0153      |\n",
            "|    n_updates            | 30           |\n",
            "|    policy_gradient_loss | -0.00568     |\n",
            "|    value_loss           | 0.00131      |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=40000, episode_reward=0.00 +/- 0.00\n",
            "Episode length: 288.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 288         |\n",
            "|    mean_reward          | 0           |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 40000       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010289989 |\n",
            "|    clip_fraction        | 0.114       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.9        |\n",
            "|    explained_variance   | 0.047950566 |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0215     |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.00652    |\n",
            "|    value_loss           | 0.00224     |\n",
            "-----------------------------------------\n",
            "New best mean reward!\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    fps             | 707   |\n",
            "|    iterations      | 5     |\n",
            "|    time_elapsed    | 57    |\n",
            "|    total_timesteps | 40960 |\n",
            "------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 692         |\n",
            "|    iterations           | 6           |\n",
            "|    time_elapsed         | 71          |\n",
            "|    total_timesteps      | 49152       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010408031 |\n",
            "|    clip_fraction        | 0.136       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.86       |\n",
            "|    explained_variance   | 0.120762944 |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.00164     |\n",
            "|    n_updates            | 50          |\n",
            "|    policy_gradient_loss | -0.00811    |\n",
            "|    value_loss           | 0.00128     |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 681         |\n",
            "|    iterations           | 7           |\n",
            "|    time_elapsed         | 84          |\n",
            "|    total_timesteps      | 57344       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009554068 |\n",
            "|    clip_fraction        | 0.121       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.83       |\n",
            "|    explained_variance   | 0.128434    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0196     |\n",
            "|    n_updates            | 60          |\n",
            "|    policy_gradient_loss | -0.00693    |\n",
            "|    value_loss           | 0.00249     |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 676         |\n",
            "|    iterations           | 8           |\n",
            "|    time_elapsed         | 96          |\n",
            "|    total_timesteps      | 65536       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011362221 |\n",
            "|    clip_fraction        | 0.128       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.83       |\n",
            "|    explained_variance   | 0.060313225 |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0185     |\n",
            "|    n_updates            | 70          |\n",
            "|    policy_gradient_loss | -0.00859    |\n",
            "|    value_loss           | 0.00155     |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 670         |\n",
            "|    iterations           | 9           |\n",
            "|    time_elapsed         | 109         |\n",
            "|    total_timesteps      | 73728       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009457553 |\n",
            "|    clip_fraction        | 0.11        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.81       |\n",
            "|    explained_variance   | 0.11171758  |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.00856    |\n",
            "|    n_updates            | 80          |\n",
            "|    policy_gradient_loss | -0.00617    |\n",
            "|    value_loss           | 0.00425     |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=80000, episode_reward=0.00 +/- 0.00\n",
            "Episode length: 288.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 288         |\n",
            "|    mean_reward          | 0           |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 80000       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010624265 |\n",
            "|    clip_fraction        | 0.124       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.78       |\n",
            "|    explained_variance   | 0.25197595  |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.00989     |\n",
            "|    n_updates            | 90          |\n",
            "|    policy_gradient_loss | -0.0108     |\n",
            "|    value_loss           | 0.0035      |\n",
            "-----------------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    fps             | 658   |\n",
            "|    iterations      | 10    |\n",
            "|    time_elapsed    | 124   |\n",
            "|    total_timesteps | 81920 |\n",
            "------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 655         |\n",
            "|    iterations           | 11          |\n",
            "|    time_elapsed         | 137         |\n",
            "|    total_timesteps      | 90112       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012545857 |\n",
            "|    clip_fraction        | 0.149       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.76       |\n",
            "|    explained_variance   | 0.2698406   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.000815    |\n",
            "|    n_updates            | 100         |\n",
            "|    policy_gradient_loss | -0.0137     |\n",
            "|    value_loss           | 0.00804     |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 653         |\n",
            "|    iterations           | 12          |\n",
            "|    time_elapsed         | 150         |\n",
            "|    total_timesteps      | 98304       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012310591 |\n",
            "|    clip_fraction        | 0.14        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.73       |\n",
            "|    explained_variance   | 0.4681217   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.00423    |\n",
            "|    n_updates            | 110         |\n",
            "|    policy_gradient_loss | -0.0107     |\n",
            "|    value_loss           | 0.00973     |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 651         |\n",
            "|    iterations           | 13          |\n",
            "|    time_elapsed         | 163         |\n",
            "|    total_timesteps      | 106496      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.014350824 |\n",
            "|    clip_fraction        | 0.159       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.7        |\n",
            "|    explained_variance   | 0.46507007  |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.00375    |\n",
            "|    n_updates            | 120         |\n",
            "|    policy_gradient_loss | -0.0164     |\n",
            "|    value_loss           | 0.0154      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 651         |\n",
            "|    iterations           | 14          |\n",
            "|    time_elapsed         | 176         |\n",
            "|    total_timesteps      | 114688      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.014301635 |\n",
            "|    clip_fraction        | 0.189       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.64       |\n",
            "|    explained_variance   | 0.5186324   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0177     |\n",
            "|    n_updates            | 130         |\n",
            "|    policy_gradient_loss | -0.0182     |\n",
            "|    value_loss           | 0.0188      |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=120000, episode_reward=0.38 +/- 0.47\n",
            "Episode length: 179.20 +/- 133.28\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 179         |\n",
            "|    mean_reward          | 0.38        |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 120000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.017319372 |\n",
            "|    clip_fraction        | 0.196       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.63       |\n",
            "|    explained_variance   | 0.6795144   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0274     |\n",
            "|    n_updates            | 140         |\n",
            "|    policy_gradient_loss | -0.0167     |\n",
            "|    value_loss           | 0.0134      |\n",
            "-----------------------------------------\n",
            "New best mean reward!\n",
            "-------------------------------\n",
            "| time/              |        |\n",
            "|    fps             | 646    |\n",
            "|    iterations      | 15     |\n",
            "|    time_elapsed    | 190    |\n",
            "|    total_timesteps | 122880 |\n",
            "-------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 645         |\n",
            "|    iterations           | 16          |\n",
            "|    time_elapsed         | 203         |\n",
            "|    total_timesteps      | 131072      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.017106272 |\n",
            "|    clip_fraction        | 0.217       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.52       |\n",
            "|    explained_variance   | 0.57495844  |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0075     |\n",
            "|    n_updates            | 150         |\n",
            "|    policy_gradient_loss | -0.0198     |\n",
            "|    value_loss           | 0.0125      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 644         |\n",
            "|    iterations           | 17          |\n",
            "|    time_elapsed         | 216         |\n",
            "|    total_timesteps      | 139264      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.020400897 |\n",
            "|    clip_fraction        | 0.277       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.46       |\n",
            "|    explained_variance   | 0.64197564  |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0333     |\n",
            "|    n_updates            | 160         |\n",
            "|    policy_gradient_loss | -0.0249     |\n",
            "|    value_loss           | 0.0108      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 642         |\n",
            "|    iterations           | 18          |\n",
            "|    time_elapsed         | 229         |\n",
            "|    total_timesteps      | 147456      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.020226208 |\n",
            "|    clip_fraction        | 0.289       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.31       |\n",
            "|    explained_variance   | 0.64490056  |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.00811     |\n",
            "|    n_updates            | 170         |\n",
            "|    policy_gradient_loss | -0.0249     |\n",
            "|    value_loss           | 0.00893     |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 641         |\n",
            "|    iterations           | 19          |\n",
            "|    time_elapsed         | 242         |\n",
            "|    total_timesteps      | 155648      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.019801985 |\n",
            "|    clip_fraction        | 0.256       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.21       |\n",
            "|    explained_variance   | 0.5953884   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0391     |\n",
            "|    n_updates            | 180         |\n",
            "|    policy_gradient_loss | -0.021      |\n",
            "|    value_loss           | 0.00629     |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=160000, episode_reward=0.57 +/- 0.47\n",
            "Episode length: 124.40 +/- 133.65\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 124         |\n",
            "|    mean_reward          | 0.571       |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 160000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.022642907 |\n",
            "|    clip_fraction        | 0.279       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.04       |\n",
            "|    explained_variance   | 0.56547683  |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0473     |\n",
            "|    n_updates            | 190         |\n",
            "|    policy_gradient_loss | -0.0251     |\n",
            "|    value_loss           | 0.00368     |\n",
            "-----------------------------------------\n",
            "New best mean reward!\n",
            "-------------------------------\n",
            "| time/              |        |\n",
            "|    fps             | 639    |\n",
            "|    iterations      | 20     |\n",
            "|    time_elapsed    | 256    |\n",
            "|    total_timesteps | 163840 |\n",
            "-------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 638        |\n",
            "|    iterations           | 21         |\n",
            "|    time_elapsed         | 269        |\n",
            "|    total_timesteps      | 172032     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.02465993 |\n",
            "|    clip_fraction        | 0.258      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.905     |\n",
            "|    explained_variance   | 0.63186306 |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | -0.066     |\n",
            "|    n_updates            | 200        |\n",
            "|    policy_gradient_loss | -0.0211    |\n",
            "|    value_loss           | 0.00245    |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 637         |\n",
            "|    iterations           | 22          |\n",
            "|    time_elapsed         | 282         |\n",
            "|    total_timesteps      | 180224      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.024674863 |\n",
            "|    clip_fraction        | 0.223       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.745      |\n",
            "|    explained_variance   | 0.67250603  |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0204     |\n",
            "|    n_updates            | 210         |\n",
            "|    policy_gradient_loss | -0.0176     |\n",
            "|    value_loss           | 0.00167     |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 636         |\n",
            "|    iterations           | 23          |\n",
            "|    time_elapsed         | 295         |\n",
            "|    total_timesteps      | 188416      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.028283782 |\n",
            "|    clip_fraction        | 0.213       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.639      |\n",
            "|    explained_variance   | 0.6430455   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0243     |\n",
            "|    n_updates            | 220         |\n",
            "|    policy_gradient_loss | -0.0168     |\n",
            "|    value_loss           | 0.00167     |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 635         |\n",
            "|    iterations           | 24          |\n",
            "|    time_elapsed         | 309         |\n",
            "|    total_timesteps      | 196608      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.049785182 |\n",
            "|    clip_fraction        | 0.199       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.525      |\n",
            "|    explained_variance   | 0.6218568   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.00138    |\n",
            "|    n_updates            | 230         |\n",
            "|    policy_gradient_loss | -0.0166     |\n",
            "|    value_loss           | 0.00159     |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=200000, episode_reward=0.77 +/- 0.39\n",
            "Episode length: 67.20 +/- 110.40\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 67.2        |\n",
            "|    mean_reward          | 0.77        |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 200000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.048213337 |\n",
            "|    clip_fraction        | 0.162       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.442      |\n",
            "|    explained_variance   | 0.6510987   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0288     |\n",
            "|    n_updates            | 240         |\n",
            "|    policy_gradient_loss | -0.00804    |\n",
            "|    value_loss           | 0.00104     |\n",
            "-----------------------------------------\n",
            "New best mean reward!\n",
            "-------------------------------\n",
            "| time/              |        |\n",
            "|    fps             | 630    |\n",
            "|    iterations      | 25     |\n",
            "|    time_elapsed    | 324    |\n",
            "|    total_timesteps | 204800 |\n",
            "-------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 630        |\n",
            "|    iterations           | 26         |\n",
            "|    time_elapsed         | 338        |\n",
            "|    total_timesteps      | 212992     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.04790776 |\n",
            "|    clip_fraction        | 0.175      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.384     |\n",
            "|    explained_variance   | 0.4545855  |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | -0.0121    |\n",
            "|    n_updates            | 250        |\n",
            "|    policy_gradient_loss | -0.0127    |\n",
            "|    value_loss           | 0.00123    |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 629         |\n",
            "|    iterations           | 27          |\n",
            "|    time_elapsed         | 351         |\n",
            "|    total_timesteps      | 221184      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.039306853 |\n",
            "|    clip_fraction        | 0.172       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.364      |\n",
            "|    explained_variance   | 0.54074347  |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.00979    |\n",
            "|    n_updates            | 260         |\n",
            "|    policy_gradient_loss | -0.0103     |\n",
            "|    value_loss           | 0.0012      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 628        |\n",
            "|    iterations           | 28         |\n",
            "|    time_elapsed         | 364        |\n",
            "|    total_timesteps      | 229376     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.03528942 |\n",
            "|    clip_fraction        | 0.137      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.318     |\n",
            "|    explained_variance   | 0.63532674 |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | -0.00272   |\n",
            "|    n_updates            | 270        |\n",
            "|    policy_gradient_loss | -0.00867   |\n",
            "|    value_loss           | 0.000933   |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 627         |\n",
            "|    iterations           | 29          |\n",
            "|    time_elapsed         | 378         |\n",
            "|    total_timesteps      | 237568      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.024930915 |\n",
            "|    clip_fraction        | 0.118       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.276      |\n",
            "|    explained_variance   | 0.6552086   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.0115      |\n",
            "|    n_updates            | 280         |\n",
            "|    policy_gradient_loss | -0.0068     |\n",
            "|    value_loss           | 0.00078     |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=240000, episode_reward=0.97 +/- 0.00\n",
            "Episode length: 9.00 +/- 1.41\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 9           |\n",
            "|    mean_reward          | 0.972       |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 240000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.045125186 |\n",
            "|    clip_fraction        | 0.147       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.273      |\n",
            "|    explained_variance   | 0.6602069   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.00304     |\n",
            "|    n_updates            | 290         |\n",
            "|    policy_gradient_loss | 0.00522     |\n",
            "|    value_loss           | 0.000566    |\n",
            "-----------------------------------------\n",
            "New best mean reward!\n",
            "Stopping training because the mean reward 0.97  is above the threshold 0.95\n",
            "Running experiment with vf_coef = 0.75, iteration 3\n",
            "Observation space: Box(0, 255, (3, 7, 7), uint8)\n",
            "Observation space shape: (3, 7, 7)\n",
            "Using cpu device\n",
            "Logging to ./ppo_minigrid_tensorboard/vf_coef_0.75/PPO_3\n",
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    fps             | 1892 |\n",
            "|    iterations      | 1    |\n",
            "|    time_elapsed    | 4    |\n",
            "|    total_timesteps | 8192 |\n",
            "-----------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 936          |\n",
            "|    iterations           | 2            |\n",
            "|    time_elapsed         | 17           |\n",
            "|    total_timesteps      | 16384        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.010830987  |\n",
            "|    clip_fraction        | 0.0782       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.94        |\n",
            "|    explained_variance   | -0.011616468 |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.0308       |\n",
            "|    n_updates            | 10           |\n",
            "|    policy_gradient_loss | -0.00634     |\n",
            "|    value_loss           | 0.000756     |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 798           |\n",
            "|    iterations           | 3             |\n",
            "|    time_elapsed         | 30            |\n",
            "|    total_timesteps      | 24576         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.01189113    |\n",
            "|    clip_fraction        | 0.108         |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -1.92         |\n",
            "|    explained_variance   | 0.00035762787 |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 0.0145        |\n",
            "|    n_updates            | 20            |\n",
            "|    policy_gradient_loss | -0.00521      |\n",
            "|    value_loss           | 0.00148       |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 750          |\n",
            "|    iterations           | 4            |\n",
            "|    time_elapsed         | 43           |\n",
            "|    total_timesteps      | 32768        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.010717051  |\n",
            "|    clip_fraction        | 0.135        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.9         |\n",
            "|    explained_variance   | -0.020560145 |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.0101      |\n",
            "|    n_updates            | 30           |\n",
            "|    policy_gradient_loss | -0.00895     |\n",
            "|    value_loss           | 0.000792     |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=40000, episode_reward=0.00 +/- 0.00\n",
            "Episode length: 288.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 288         |\n",
            "|    mean_reward          | 0           |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 40000       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.015107291 |\n",
            "|    clip_fraction        | 0.163       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.88       |\n",
            "|    explained_variance   | -2.1427658  |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.00552    |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.0119     |\n",
            "|    value_loss           | 1.65e-05    |\n",
            "-----------------------------------------\n",
            "New best mean reward!\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    fps             | 703   |\n",
            "|    iterations      | 5     |\n",
            "|    time_elapsed    | 58    |\n",
            "|    total_timesteps | 40960 |\n",
            "------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 686          |\n",
            "|    iterations           | 6            |\n",
            "|    time_elapsed         | 71           |\n",
            "|    total_timesteps      | 49152        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.009879259  |\n",
            "|    clip_fraction        | 0.113        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.86        |\n",
            "|    explained_variance   | -0.005640745 |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.0153      |\n",
            "|    n_updates            | 50           |\n",
            "|    policy_gradient_loss | -0.00456     |\n",
            "|    value_loss           | 0.000656     |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 677           |\n",
            "|    iterations           | 7             |\n",
            "|    time_elapsed         | 84            |\n",
            "|    total_timesteps      | 57344         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.011084939   |\n",
            "|    clip_fraction        | 0.102         |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -1.82         |\n",
            "|    explained_variance   | -0.0063080788 |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | -0.0152       |\n",
            "|    n_updates            | 60            |\n",
            "|    policy_gradient_loss | -0.0056       |\n",
            "|    value_loss           | 0.000635      |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 669          |\n",
            "|    iterations           | 8            |\n",
            "|    time_elapsed         | 97           |\n",
            "|    total_timesteps      | 65536        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.014835221  |\n",
            "|    clip_fraction        | 0.112        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.83        |\n",
            "|    explained_variance   | -0.109936714 |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.0114      |\n",
            "|    n_updates            | 70           |\n",
            "|    policy_gradient_loss | -0.00784     |\n",
            "|    value_loss           | 0.000452     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 663         |\n",
            "|    iterations           | 9           |\n",
            "|    time_elapsed         | 111         |\n",
            "|    total_timesteps      | 73728       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.016341068 |\n",
            "|    clip_fraction        | 0.161       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.8        |\n",
            "|    explained_variance   | -1.2111537  |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.00736     |\n",
            "|    n_updates            | 80          |\n",
            "|    policy_gradient_loss | -0.00948    |\n",
            "|    value_loss           | 1.97e-05    |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=80000, episode_reward=0.00 +/- 0.00\n",
            "Episode length: 288.00 +/- 0.00\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 288          |\n",
            "|    mean_reward          | 0            |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 80000        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0113082295 |\n",
            "|    clip_fraction        | 0.134        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.78        |\n",
            "|    explained_variance   | -0.09557271  |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.025       |\n",
            "|    n_updates            | 90           |\n",
            "|    policy_gradient_loss | -0.00932     |\n",
            "|    value_loss           | 6.51e-05     |\n",
            "------------------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    fps             | 653   |\n",
            "|    iterations      | 10    |\n",
            "|    time_elapsed    | 125   |\n",
            "|    total_timesteps | 81920 |\n",
            "------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 650         |\n",
            "|    iterations           | 11          |\n",
            "|    time_elapsed         | 138         |\n",
            "|    total_timesteps      | 90112       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.022071306 |\n",
            "|    clip_fraction        | 0.201       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.78       |\n",
            "|    explained_variance   | -5.441347   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0763     |\n",
            "|    n_updates            | 100         |\n",
            "|    policy_gradient_loss | -0.0128     |\n",
            "|    value_loss           | 5.37e-06    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 647         |\n",
            "|    iterations           | 12          |\n",
            "|    time_elapsed         | 151         |\n",
            "|    total_timesteps      | 98304       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012584802 |\n",
            "|    clip_fraction        | 0.141       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.73       |\n",
            "|    explained_variance   | 0.004230261 |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0266     |\n",
            "|    n_updates            | 110         |\n",
            "|    policy_gradient_loss | -0.00698    |\n",
            "|    value_loss           | 0.0002      |\n",
            "-----------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 645           |\n",
            "|    iterations           | 13            |\n",
            "|    time_elapsed         | 165           |\n",
            "|    total_timesteps      | 106496        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.012961599   |\n",
            "|    clip_fraction        | 0.169         |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -1.72         |\n",
            "|    explained_variance   | -0.0071891546 |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | -0.00109      |\n",
            "|    n_updates            | 120           |\n",
            "|    policy_gradient_loss | -0.0104       |\n",
            "|    value_loss           | 0.000315      |\n",
            "-------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 643         |\n",
            "|    iterations           | 14          |\n",
            "|    time_elapsed         | 178         |\n",
            "|    total_timesteps      | 114688      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011564102 |\n",
            "|    clip_fraction        | 0.129       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.71       |\n",
            "|    explained_variance   | 0.006366968 |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.00649     |\n",
            "|    n_updates            | 130         |\n",
            "|    policy_gradient_loss | -0.00536    |\n",
            "|    value_loss           | 0.00291     |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=120000, episode_reward=0.00 +/- 0.00\n",
            "Episode length: 288.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 288         |\n",
            "|    mean_reward          | 0           |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 120000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012162399 |\n",
            "|    clip_fraction        | 0.149       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.66       |\n",
            "|    explained_variance   | 0.07667887  |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0153     |\n",
            "|    n_updates            | 140         |\n",
            "|    policy_gradient_loss | -0.00723    |\n",
            "|    value_loss           | 0.00337     |\n",
            "-----------------------------------------\n",
            "-------------------------------\n",
            "| time/              |        |\n",
            "|    fps             | 636    |\n",
            "|    iterations      | 15     |\n",
            "|    time_elapsed    | 192    |\n",
            "|    total_timesteps | 122880 |\n",
            "-------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 636         |\n",
            "|    iterations           | 16          |\n",
            "|    time_elapsed         | 206         |\n",
            "|    total_timesteps      | 131072      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010490406 |\n",
            "|    clip_fraction        | 0.14        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.62       |\n",
            "|    explained_variance   | 0.12664485  |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.00863    |\n",
            "|    n_updates            | 150         |\n",
            "|    policy_gradient_loss | -0.00751    |\n",
            "|    value_loss           | 0.00545     |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 635         |\n",
            "|    iterations           | 17          |\n",
            "|    time_elapsed         | 219         |\n",
            "|    total_timesteps      | 139264      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011761567 |\n",
            "|    clip_fraction        | 0.152       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.57       |\n",
            "|    explained_variance   | 0.25485426  |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0221     |\n",
            "|    n_updates            | 160         |\n",
            "|    policy_gradient_loss | -0.0109     |\n",
            "|    value_loss           | 0.00586     |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 634         |\n",
            "|    iterations           | 18          |\n",
            "|    time_elapsed         | 232         |\n",
            "|    total_timesteps      | 147456      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010176711 |\n",
            "|    clip_fraction        | 0.127       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.51       |\n",
            "|    explained_variance   | 0.30877298  |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.0112      |\n",
            "|    n_updates            | 170         |\n",
            "|    policy_gradient_loss | -0.00648    |\n",
            "|    value_loss           | 0.00618     |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 633         |\n",
            "|    iterations           | 19          |\n",
            "|    time_elapsed         | 245         |\n",
            "|    total_timesteps      | 155648      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010929662 |\n",
            "|    clip_fraction        | 0.121       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.5        |\n",
            "|    explained_variance   | 0.42895353  |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.00134     |\n",
            "|    n_updates            | 180         |\n",
            "|    policy_gradient_loss | -0.00742    |\n",
            "|    value_loss           | 0.00732     |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=160000, episode_reward=0.00 +/- 0.00\n",
            "Episode length: 288.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 288         |\n",
            "|    mean_reward          | 0           |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 160000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013123097 |\n",
            "|    clip_fraction        | 0.158       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.48       |\n",
            "|    explained_variance   | 0.45347506  |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.000536   |\n",
            "|    n_updates            | 190         |\n",
            "|    policy_gradient_loss | -0.0109     |\n",
            "|    value_loss           | 0.0115      |\n",
            "-----------------------------------------\n",
            "-------------------------------\n",
            "| time/              |        |\n",
            "|    fps             | 629    |\n",
            "|    iterations      | 20     |\n",
            "|    time_elapsed    | 260    |\n",
            "|    total_timesteps | 163840 |\n",
            "-------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 629         |\n",
            "|    iterations           | 21          |\n",
            "|    time_elapsed         | 273         |\n",
            "|    total_timesteps      | 172032      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013002934 |\n",
            "|    clip_fraction        | 0.136       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.45       |\n",
            "|    explained_variance   | 0.49821526  |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.00444     |\n",
            "|    n_updates            | 200         |\n",
            "|    policy_gradient_loss | -0.00839    |\n",
            "|    value_loss           | 0.0121      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 629         |\n",
            "|    iterations           | 22          |\n",
            "|    time_elapsed         | 286         |\n",
            "|    total_timesteps      | 180224      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013193505 |\n",
            "|    clip_fraction        | 0.146       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.43       |\n",
            "|    explained_variance   | 0.43364257  |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0105     |\n",
            "|    n_updates            | 210         |\n",
            "|    policy_gradient_loss | -0.0111     |\n",
            "|    value_loss           | 0.0184      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 628         |\n",
            "|    iterations           | 23          |\n",
            "|    time_elapsed         | 299         |\n",
            "|    total_timesteps      | 188416      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.014953316 |\n",
            "|    clip_fraction        | 0.159       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.42       |\n",
            "|    explained_variance   | 0.4305299   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0306     |\n",
            "|    n_updates            | 220         |\n",
            "|    policy_gradient_loss | -0.0102     |\n",
            "|    value_loss           | 0.0197      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 628         |\n",
            "|    iterations           | 24          |\n",
            "|    time_elapsed         | 313         |\n",
            "|    total_timesteps      | 196608      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.015971523 |\n",
            "|    clip_fraction        | 0.168       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.41       |\n",
            "|    explained_variance   | 0.48663044  |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.00893    |\n",
            "|    n_updates            | 230         |\n",
            "|    policy_gradient_loss | -0.0132     |\n",
            "|    value_loss           | 0.0206      |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=200000, episode_reward=0.39 +/- 0.47\n",
            "Episode length: 177.00 +/- 135.96\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 177         |\n",
            "|    mean_reward          | 0.387       |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 200000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.015545551 |\n",
            "|    clip_fraction        | 0.198       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.32       |\n",
            "|    explained_variance   | 0.594661    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.0106      |\n",
            "|    n_updates            | 240         |\n",
            "|    policy_gradient_loss | -0.0173     |\n",
            "|    value_loss           | 0.0223      |\n",
            "-----------------------------------------\n",
            "New best mean reward!\n",
            "-------------------------------\n",
            "| time/              |        |\n",
            "|    fps             | 625    |\n",
            "|    iterations      | 25     |\n",
            "|    time_elapsed    | 327    |\n",
            "|    total_timesteps | 204800 |\n",
            "-------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 625         |\n",
            "|    iterations           | 26          |\n",
            "|    time_elapsed         | 340         |\n",
            "|    total_timesteps      | 212992      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.016398828 |\n",
            "|    clip_fraction        | 0.208       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.3        |\n",
            "|    explained_variance   | 0.69680077  |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.00502     |\n",
            "|    n_updates            | 250         |\n",
            "|    policy_gradient_loss | -0.0174     |\n",
            "|    value_loss           | 0.018       |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 625        |\n",
            "|    iterations           | 27         |\n",
            "|    time_elapsed         | 353        |\n",
            "|    total_timesteps      | 221184     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.0192134  |\n",
            "|    clip_fraction        | 0.222      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -1.18      |\n",
            "|    explained_variance   | 0.71642613 |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.00757    |\n",
            "|    n_updates            | 260        |\n",
            "|    policy_gradient_loss | -0.0198    |\n",
            "|    value_loss           | 0.0167     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 624         |\n",
            "|    iterations           | 28          |\n",
            "|    time_elapsed         | 367         |\n",
            "|    total_timesteps      | 229376      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.021440439 |\n",
            "|    clip_fraction        | 0.225       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.04       |\n",
            "|    explained_variance   | 0.5924897   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0272     |\n",
            "|    n_updates            | 270         |\n",
            "|    policy_gradient_loss | -0.0195     |\n",
            "|    value_loss           | 0.0124      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 624         |\n",
            "|    iterations           | 29          |\n",
            "|    time_elapsed         | 380         |\n",
            "|    total_timesteps      | 237568      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.019410102 |\n",
            "|    clip_fraction        | 0.195       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.935      |\n",
            "|    explained_variance   | 0.5442027   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.018      |\n",
            "|    n_updates            | 280         |\n",
            "|    policy_gradient_loss | -0.0145     |\n",
            "|    value_loss           | 0.0059      |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=240000, episode_reward=0.77 +/- 0.39\n",
            "Episode length: 65.80 +/- 111.10\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 65.8        |\n",
            "|    mean_reward          | 0.774       |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 240000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.019427776 |\n",
            "|    clip_fraction        | 0.211       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.793      |\n",
            "|    explained_variance   | 0.4926327   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0337     |\n",
            "|    n_updates            | 290         |\n",
            "|    policy_gradient_loss | -0.018      |\n",
            "|    value_loss           | 0.00304     |\n",
            "-----------------------------------------\n",
            "New best mean reward!\n",
            "-------------------------------\n",
            "| time/              |        |\n",
            "|    fps             | 623    |\n",
            "|    iterations      | 30     |\n",
            "|    time_elapsed    | 393    |\n",
            "|    total_timesteps | 245760 |\n",
            "-------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 623        |\n",
            "|    iterations           | 31         |\n",
            "|    time_elapsed         | 407        |\n",
            "|    total_timesteps      | 253952     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.02798134 |\n",
            "|    clip_fraction        | 0.226      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.706     |\n",
            "|    explained_variance   | 0.56052405 |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | -0.0324    |\n",
            "|    n_updates            | 300        |\n",
            "|    policy_gradient_loss | -0.0212    |\n",
            "|    value_loss           | 0.00209    |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 623         |\n",
            "|    iterations           | 32          |\n",
            "|    time_elapsed         | 420         |\n",
            "|    total_timesteps      | 262144      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.036383387 |\n",
            "|    clip_fraction        | 0.212       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.579      |\n",
            "|    explained_variance   | 0.6723274   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.013      |\n",
            "|    n_updates            | 310         |\n",
            "|    policy_gradient_loss | -0.0204     |\n",
            "|    value_loss           | 0.00151     |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 622         |\n",
            "|    iterations           | 33          |\n",
            "|    time_elapsed         | 433         |\n",
            "|    total_timesteps      | 270336      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.024153698 |\n",
            "|    clip_fraction        | 0.166       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.473      |\n",
            "|    explained_variance   | 0.6928959   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0464     |\n",
            "|    n_updates            | 320         |\n",
            "|    policy_gradient_loss | -0.0165     |\n",
            "|    value_loss           | 0.00112     |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 622         |\n",
            "|    iterations           | 34          |\n",
            "|    time_elapsed         | 447         |\n",
            "|    total_timesteps      | 278528      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.024267707 |\n",
            "|    clip_fraction        | 0.138       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.376      |\n",
            "|    explained_variance   | 0.65891814  |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.00812    |\n",
            "|    n_updates            | 330         |\n",
            "|    policy_gradient_loss | -0.0137     |\n",
            "|    value_loss           | 0.000865    |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=280000, episode_reward=0.39 +/- 0.48\n",
            "Episode length: 176.40 +/- 136.70\n",
            "----------------------------------------\n",
            "| eval/                   |            |\n",
            "|    mean_ep_length       | 176        |\n",
            "|    mean_reward          | 0.389      |\n",
            "| time/                   |            |\n",
            "|    total_timesteps      | 280000     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.0821349  |\n",
            "|    clip_fraction        | 0.13       |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.28      |\n",
            "|    explained_variance   | 0.67739093 |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | -0.047     |\n",
            "|    n_updates            | 340        |\n",
            "|    policy_gradient_loss | 0.00343    |\n",
            "|    value_loss           | 0.000508   |\n",
            "----------------------------------------\n",
            "-------------------------------\n",
            "| time/              |        |\n",
            "|    fps             | 621    |\n",
            "|    iterations      | 35     |\n",
            "|    time_elapsed    | 461    |\n",
            "|    total_timesteps | 286720 |\n",
            "-------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 621        |\n",
            "|    iterations           | 36         |\n",
            "|    time_elapsed         | 474        |\n",
            "|    total_timesteps      | 294912     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.06325817 |\n",
            "|    clip_fraction        | 0.214      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.292     |\n",
            "|    explained_variance   | 0.5510802  |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | -0.0502    |\n",
            "|    n_updates            | 350        |\n",
            "|    policy_gradient_loss | -0.0137    |\n",
            "|    value_loss           | 0.0008     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 621        |\n",
            "|    iterations           | 37         |\n",
            "|    time_elapsed         | 487        |\n",
            "|    total_timesteps      | 303104     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.07823743 |\n",
            "|    clip_fraction        | 0.174      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.262     |\n",
            "|    explained_variance   | 0.6172899  |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.0533     |\n",
            "|    n_updates            | 360        |\n",
            "|    policy_gradient_loss | -0.00418   |\n",
            "|    value_loss           | 0.000742   |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 621        |\n",
            "|    iterations           | 38         |\n",
            "|    time_elapsed         | 501        |\n",
            "|    total_timesteps      | 311296     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.04729476 |\n",
            "|    clip_fraction        | 0.204      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.278     |\n",
            "|    explained_variance   | 0.4938575  |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | -0.0375    |\n",
            "|    n_updates            | 370        |\n",
            "|    policy_gradient_loss | 0.0147     |\n",
            "|    value_loss           | 0.000969   |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 620        |\n",
            "|    iterations           | 39         |\n",
            "|    time_elapsed         | 514        |\n",
            "|    total_timesteps      | 319488     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.06674448 |\n",
            "|    clip_fraction        | 0.176      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.223     |\n",
            "|    explained_variance   | 0.5649628  |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | -0.0215    |\n",
            "|    n_updates            | 380        |\n",
            "|    policy_gradient_loss | -0.0187    |\n",
            "|    value_loss           | 0.00133    |\n",
            "----------------------------------------\n",
            "Eval num_timesteps=320000, episode_reward=0.77 +/- 0.39\n",
            "Episode length: 65.80 +/- 111.10\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 65.8        |\n",
            "|    mean_reward          | 0.774       |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 320000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.045583494 |\n",
            "|    clip_fraction        | 0.19        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.272      |\n",
            "|    explained_variance   | 0.6333177   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0365     |\n",
            "|    n_updates            | 390         |\n",
            "|    policy_gradient_loss | -0.0114     |\n",
            "|    value_loss           | 0.000559    |\n",
            "-----------------------------------------\n",
            "-------------------------------\n",
            "| time/              |        |\n",
            "|    fps             | 620    |\n",
            "|    iterations      | 40     |\n",
            "|    time_elapsed    | 528    |\n",
            "|    total_timesteps | 327680 |\n",
            "-------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 620        |\n",
            "|    iterations           | 41         |\n",
            "|    time_elapsed         | 541        |\n",
            "|    total_timesteps      | 335872     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.08641136 |\n",
            "|    clip_fraction        | 0.258      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.26      |\n",
            "|    explained_variance   | 0.34984004 |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | -0.0298    |\n",
            "|    n_updates            | 400        |\n",
            "|    policy_gradient_loss | 0.0518     |\n",
            "|    value_loss           | 0.00208    |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 620        |\n",
            "|    iterations           | 42         |\n",
            "|    time_elapsed         | 554        |\n",
            "|    total_timesteps      | 344064     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.0496065  |\n",
            "|    clip_fraction        | 0.124      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.22      |\n",
            "|    explained_variance   | 0.46299875 |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | -0.0332    |\n",
            "|    n_updates            | 410        |\n",
            "|    policy_gradient_loss | -0.00514   |\n",
            "|    value_loss           | 0.000676   |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 619         |\n",
            "|    iterations           | 43          |\n",
            "|    time_elapsed         | 568         |\n",
            "|    total_timesteps      | 352256      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.037266452 |\n",
            "|    clip_fraction        | 0.212       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.337      |\n",
            "|    explained_variance   | 0.54221773  |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0641     |\n",
            "|    n_updates            | 420         |\n",
            "|    policy_gradient_loss | -0.0231     |\n",
            "|    value_loss           | 0.00134     |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=360000, episode_reward=0.97 +/- 0.01\n",
            "Episode length: 8.80 +/- 2.23\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 8.8         |\n",
            "|    mean_reward          | 0.973       |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 360000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.034968268 |\n",
            "|    clip_fraction        | 0.163       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.264      |\n",
            "|    explained_variance   | 0.659583    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0468     |\n",
            "|    n_updates            | 430         |\n",
            "|    policy_gradient_loss | -0.0159     |\n",
            "|    value_loss           | 0.00074     |\n",
            "-----------------------------------------\n",
            "New best mean reward!\n",
            "Stopping training because the mean reward 0.97  is above the threshold 0.95\n",
            "Running experiment with vf_coef = 1.0, iteration 1\n",
            "Observation space: Box(0, 255, (3, 7, 7), uint8)\n",
            "Observation space shape: (3, 7, 7)\n",
            "Using cpu device\n",
            "Logging to ./ppo_minigrid_tensorboard/vf_coef_1.0/PPO_1\n",
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    fps             | 1876 |\n",
            "|    iterations      | 1    |\n",
            "|    time_elapsed    | 4    |\n",
            "|    total_timesteps | 8192 |\n",
            "-----------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 937          |\n",
            "|    iterations           | 2            |\n",
            "|    time_elapsed         | 17           |\n",
            "|    total_timesteps      | 16384        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.010926312  |\n",
            "|    clip_fraction        | 0.0626       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.94        |\n",
            "|    explained_variance   | -0.016927958 |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.0333      |\n",
            "|    n_updates            | 10           |\n",
            "|    policy_gradient_loss | -0.00497     |\n",
            "|    value_loss           | 0.000552     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 798         |\n",
            "|    iterations           | 3           |\n",
            "|    time_elapsed         | 30          |\n",
            "|    total_timesteps      | 24576       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.016028622 |\n",
            "|    clip_fraction        | 0.136       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.91       |\n",
            "|    explained_variance   | -0.14434826 |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0358     |\n",
            "|    n_updates            | 20          |\n",
            "|    policy_gradient_loss | -0.0059     |\n",
            "|    value_loss           | 0.000309    |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 746        |\n",
            "|    iterations           | 4          |\n",
            "|    time_elapsed         | 43         |\n",
            "|    total_timesteps      | 32768      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01264508 |\n",
            "|    clip_fraction        | 0.156      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -1.89      |\n",
            "|    explained_variance   | -0.1394453 |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | -0.0522    |\n",
            "|    n_updates            | 30         |\n",
            "|    policy_gradient_loss | -0.0112    |\n",
            "|    value_loss           | 7.73e-05   |\n",
            "----------------------------------------\n",
            "Eval num_timesteps=40000, episode_reward=0.00 +/- 0.00\n",
            "Episode length: 288.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 288         |\n",
            "|    mean_reward          | 0           |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 40000       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008872166 |\n",
            "|    clip_fraction        | 0.105       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.87       |\n",
            "|    explained_variance   | 0.031284392 |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0118     |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.00535    |\n",
            "|    value_loss           | 0.00246     |\n",
            "-----------------------------------------\n",
            "New best mean reward!\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    fps             | 699   |\n",
            "|    iterations      | 5     |\n",
            "|    time_elapsed    | 58    |\n",
            "|    total_timesteps | 40960 |\n",
            "------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 687         |\n",
            "|    iterations           | 6           |\n",
            "|    time_elapsed         | 71          |\n",
            "|    total_timesteps      | 49152       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009191191 |\n",
            "|    clip_fraction        | 0.0817      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.86       |\n",
            "|    explained_variance   | 0.07199794  |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.00933     |\n",
            "|    n_updates            | 50          |\n",
            "|    policy_gradient_loss | -0.00493    |\n",
            "|    value_loss           | 0.00151     |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 676         |\n",
            "|    iterations           | 7           |\n",
            "|    time_elapsed         | 84          |\n",
            "|    total_timesteps      | 57344       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010680687 |\n",
            "|    clip_fraction        | 0.124       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.83       |\n",
            "|    explained_variance   | 0.18719673  |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.024      |\n",
            "|    n_updates            | 60          |\n",
            "|    policy_gradient_loss | -0.00783    |\n",
            "|    value_loss           | 0.00167     |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 668         |\n",
            "|    iterations           | 8           |\n",
            "|    time_elapsed         | 98          |\n",
            "|    total_timesteps      | 65536       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008794768 |\n",
            "|    clip_fraction        | 0.103       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.81       |\n",
            "|    explained_variance   | 0.14805132  |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.00343    |\n",
            "|    n_updates            | 70          |\n",
            "|    policy_gradient_loss | -0.0076     |\n",
            "|    value_loss           | 0.00424     |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 663        |\n",
            "|    iterations           | 9          |\n",
            "|    time_elapsed         | 111        |\n",
            "|    total_timesteps      | 73728      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00988109 |\n",
            "|    clip_fraction        | 0.0968     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -1.8       |\n",
            "|    explained_variance   | 0.26345116 |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | -0.0189    |\n",
            "|    n_updates            | 80         |\n",
            "|    policy_gradient_loss | -0.00752   |\n",
            "|    value_loss           | 0.0033     |\n",
            "----------------------------------------\n",
            "Eval num_timesteps=80000, episode_reward=0.20 +/- 0.39\n",
            "Episode length: 231.80 +/- 112.40\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 232         |\n",
            "|    mean_reward          | 0.196       |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 80000       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010085206 |\n",
            "|    clip_fraction        | 0.129       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.77       |\n",
            "|    explained_variance   | 0.35744327  |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.00997    |\n",
            "|    n_updates            | 90          |\n",
            "|    policy_gradient_loss | -0.0117     |\n",
            "|    value_loss           | 0.00762     |\n",
            "-----------------------------------------\n",
            "New best mean reward!\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    fps             | 653   |\n",
            "|    iterations      | 10    |\n",
            "|    time_elapsed    | 125   |\n",
            "|    total_timesteps | 81920 |\n",
            "------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 650         |\n",
            "|    iterations           | 11          |\n",
            "|    time_elapsed         | 138         |\n",
            "|    total_timesteps      | 90112       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011534023 |\n",
            "|    clip_fraction        | 0.133       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.75       |\n",
            "|    explained_variance   | 0.4467523   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0237     |\n",
            "|    n_updates            | 100         |\n",
            "|    policy_gradient_loss | -0.0143     |\n",
            "|    value_loss           | 0.0153      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 650         |\n",
            "|    iterations           | 12          |\n",
            "|    time_elapsed         | 151         |\n",
            "|    total_timesteps      | 98304       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012802978 |\n",
            "|    clip_fraction        | 0.155       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.7        |\n",
            "|    explained_variance   | 0.47914368  |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0253     |\n",
            "|    n_updates            | 110         |\n",
            "|    policy_gradient_loss | -0.0162     |\n",
            "|    value_loss           | 0.0186      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 648         |\n",
            "|    iterations           | 13          |\n",
            "|    time_elapsed         | 164         |\n",
            "|    total_timesteps      | 106496      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.016281161 |\n",
            "|    clip_fraction        | 0.18        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.69       |\n",
            "|    explained_variance   | 0.5216435   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.0111      |\n",
            "|    n_updates            | 120         |\n",
            "|    policy_gradient_loss | -0.0166     |\n",
            "|    value_loss           | 0.0155      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 642         |\n",
            "|    iterations           | 14          |\n",
            "|    time_elapsed         | 178         |\n",
            "|    total_timesteps      | 114688      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.016526405 |\n",
            "|    clip_fraction        | 0.186       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.66       |\n",
            "|    explained_variance   | 0.60376996  |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.0181      |\n",
            "|    n_updates            | 130         |\n",
            "|    policy_gradient_loss | -0.0172     |\n",
            "|    value_loss           | 0.017       |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=120000, episode_reward=0.39 +/- 0.48\n",
            "Episode length: 175.60 +/- 137.66\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 176         |\n",
            "|    mean_reward          | 0.391       |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 120000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.018354662 |\n",
            "|    clip_fraction        | 0.214       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.56       |\n",
            "|    explained_variance   | 0.5884001   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0204     |\n",
            "|    n_updates            | 140         |\n",
            "|    policy_gradient_loss | -0.0186     |\n",
            "|    value_loss           | 0.0157      |\n",
            "-----------------------------------------\n",
            "New best mean reward!\n",
            "-------------------------------\n",
            "| time/              |        |\n",
            "|    fps             | 634    |\n",
            "|    iterations      | 15     |\n",
            "|    time_elapsed    | 193    |\n",
            "|    total_timesteps | 122880 |\n",
            "-------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 627         |\n",
            "|    iterations           | 16          |\n",
            "|    time_elapsed         | 208         |\n",
            "|    total_timesteps      | 131072      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.020164158 |\n",
            "|    clip_fraction        | 0.257       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.43       |\n",
            "|    explained_variance   | 0.6137432   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0128     |\n",
            "|    n_updates            | 150         |\n",
            "|    policy_gradient_loss | -0.0233     |\n",
            "|    value_loss           | 0.0124      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 626         |\n",
            "|    iterations           | 17          |\n",
            "|    time_elapsed         | 222         |\n",
            "|    total_timesteps      | 139264      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.021475036 |\n",
            "|    clip_fraction        | 0.289       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.32       |\n",
            "|    explained_variance   | 0.6118442   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0161     |\n",
            "|    n_updates            | 160         |\n",
            "|    policy_gradient_loss | -0.0254     |\n",
            "|    value_loss           | 0.00763     |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 625         |\n",
            "|    iterations           | 18          |\n",
            "|    time_elapsed         | 235         |\n",
            "|    total_timesteps      | 147456      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.022752501 |\n",
            "|    clip_fraction        | 0.274       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.21       |\n",
            "|    explained_variance   | 0.61670494  |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0352     |\n",
            "|    n_updates            | 170         |\n",
            "|    policy_gradient_loss | -0.0234     |\n",
            "|    value_loss           | 0.00475     |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 624         |\n",
            "|    iterations           | 19          |\n",
            "|    time_elapsed         | 249         |\n",
            "|    total_timesteps      | 155648      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.020308878 |\n",
            "|    clip_fraction        | 0.263       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.09       |\n",
            "|    explained_variance   | 0.5478908   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0124     |\n",
            "|    n_updates            | 180         |\n",
            "|    policy_gradient_loss | -0.0218     |\n",
            "|    value_loss           | 0.00285     |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=160000, episode_reward=0.97 +/- 0.01\n",
            "Episode length: 10.80 +/- 2.14\n",
            "----------------------------------------\n",
            "| eval/                   |            |\n",
            "|    mean_ep_length       | 10.8       |\n",
            "|    mean_reward          | 0.966      |\n",
            "| time/                   |            |\n",
            "|    total_timesteps      | 160000     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.03409424 |\n",
            "|    clip_fraction        | 0.264      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.947     |\n",
            "|    explained_variance   | 0.61230624 |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | -0.0378    |\n",
            "|    n_updates            | 190        |\n",
            "|    policy_gradient_loss | -0.0182    |\n",
            "|    value_loss           | 0.00187    |\n",
            "----------------------------------------\n",
            "New best mean reward!\n",
            "Stopping training because the mean reward 0.97  is above the threshold 0.95\n",
            "Running experiment with vf_coef = 1.0, iteration 2\n",
            "Observation space: Box(0, 255, (3, 7, 7), uint8)\n",
            "Observation space shape: (3, 7, 7)\n",
            "Using cpu device\n",
            "Logging to ./ppo_minigrid_tensorboard/vf_coef_1.0/PPO_2\n",
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    fps             | 1778 |\n",
            "|    iterations      | 1    |\n",
            "|    time_elapsed    | 4    |\n",
            "|    total_timesteps | 8192 |\n",
            "-----------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 930          |\n",
            "|    iterations           | 2            |\n",
            "|    time_elapsed         | 17           |\n",
            "|    total_timesteps      | 16384        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.012840582  |\n",
            "|    clip_fraction        | 0.0499       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.94        |\n",
            "|    explained_variance   | -0.038632035 |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.0237       |\n",
            "|    n_updates            | 10           |\n",
            "|    policy_gradient_loss | -0.00405     |\n",
            "|    value_loss           | 0.000829     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 792          |\n",
            "|    iterations           | 3            |\n",
            "|    time_elapsed         | 31           |\n",
            "|    total_timesteps      | 24576        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.009505305  |\n",
            "|    clip_fraction        | 0.0971       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.93        |\n",
            "|    explained_variance   | -0.031165004 |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.00693     |\n",
            "|    n_updates            | 20           |\n",
            "|    policy_gradient_loss | -0.00595     |\n",
            "|    value_loss           | 0.000653     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 730          |\n",
            "|    iterations           | 4            |\n",
            "|    time_elapsed         | 44           |\n",
            "|    total_timesteps      | 32768        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0107387435 |\n",
            "|    clip_fraction        | 0.105        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.92        |\n",
            "|    explained_variance   | 0.0076760054 |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.00344      |\n",
            "|    n_updates            | 30           |\n",
            "|    policy_gradient_loss | -0.00683     |\n",
            "|    value_loss           | 0.000644     |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=40000, episode_reward=0.00 +/- 0.00\n",
            "Episode length: 288.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 288         |\n",
            "|    mean_reward          | 0           |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 40000       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012949517 |\n",
            "|    clip_fraction        | 0.145       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.88       |\n",
            "|    explained_variance   | 0.064989865 |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0111     |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.00917    |\n",
            "|    value_loss           | 0.000452    |\n",
            "-----------------------------------------\n",
            "New best mean reward!\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    fps             | 688   |\n",
            "|    iterations      | 5     |\n",
            "|    time_elapsed    | 59    |\n",
            "|    total_timesteps | 40960 |\n",
            "------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 674          |\n",
            "|    iterations           | 6            |\n",
            "|    time_elapsed         | 72           |\n",
            "|    total_timesteps      | 49152        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.01140432   |\n",
            "|    clip_fraction        | 0.103        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.85        |\n",
            "|    explained_variance   | -0.113802075 |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.00465     |\n",
            "|    n_updates            | 50           |\n",
            "|    policy_gradient_loss | -0.00841     |\n",
            "|    value_loss           | 1.36e-05     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 665         |\n",
            "|    iterations           | 7           |\n",
            "|    time_elapsed         | 86          |\n",
            "|    total_timesteps      | 57344       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.016084515 |\n",
            "|    clip_fraction        | 0.171       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.83       |\n",
            "|    explained_variance   | 0.05651194  |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.00798    |\n",
            "|    n_updates            | 60          |\n",
            "|    policy_gradient_loss | -0.00921    |\n",
            "|    value_loss           | 0.000319    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 657          |\n",
            "|    iterations           | 8            |\n",
            "|    time_elapsed         | 99           |\n",
            "|    total_timesteps      | 65536        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0155796055 |\n",
            "|    clip_fraction        | 0.16         |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.83        |\n",
            "|    explained_variance   | 0.17348361   |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.0307      |\n",
            "|    n_updates            | 70           |\n",
            "|    policy_gradient_loss | -0.0101      |\n",
            "|    value_loss           | 0.000139     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 653         |\n",
            "|    iterations           | 9           |\n",
            "|    time_elapsed         | 112         |\n",
            "|    total_timesteps      | 73728       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011218121 |\n",
            "|    clip_fraction        | 0.12        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.84       |\n",
            "|    explained_variance   | 0.03265345  |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.013      |\n",
            "|    n_updates            | 80          |\n",
            "|    policy_gradient_loss | -0.00602    |\n",
            "|    value_loss           | 0.00376     |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=80000, episode_reward=0.00 +/- 0.00\n",
            "Episode length: 288.00 +/- 0.00\n",
            "----------------------------------------\n",
            "| eval/                   |            |\n",
            "|    mean_ep_length       | 288        |\n",
            "|    mean_reward          | 0          |\n",
            "| time/                   |            |\n",
            "|    total_timesteps      | 80000      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01410272 |\n",
            "|    clip_fraction        | 0.177      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -1.81      |\n",
            "|    explained_variance   | 0.0823791  |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | -0.0173    |\n",
            "|    n_updates            | 90         |\n",
            "|    policy_gradient_loss | -0.00904   |\n",
            "|    value_loss           | 0.00217    |\n",
            "----------------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    fps             | 640   |\n",
            "|    iterations      | 10    |\n",
            "|    time_elapsed    | 127   |\n",
            "|    total_timesteps | 81920 |\n",
            "------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 637         |\n",
            "|    iterations           | 11          |\n",
            "|    time_elapsed         | 141         |\n",
            "|    total_timesteps      | 90112       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.014212481 |\n",
            "|    clip_fraction        | 0.136       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.8        |\n",
            "|    explained_variance   | 0.06547624  |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0583     |\n",
            "|    n_updates            | 100         |\n",
            "|    policy_gradient_loss | -0.00767    |\n",
            "|    value_loss           | 0.00322     |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 635         |\n",
            "|    iterations           | 12          |\n",
            "|    time_elapsed         | 154         |\n",
            "|    total_timesteps      | 98304       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009221389 |\n",
            "|    clip_fraction        | 0.104       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.78       |\n",
            "|    explained_variance   | 0.2649272   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.00235     |\n",
            "|    n_updates            | 110         |\n",
            "|    policy_gradient_loss | -0.00811    |\n",
            "|    value_loss           | 0.0015      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 633         |\n",
            "|    iterations           | 13          |\n",
            "|    time_elapsed         | 168         |\n",
            "|    total_timesteps      | 106496      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010781197 |\n",
            "|    clip_fraction        | 0.115       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.75       |\n",
            "|    explained_variance   | 0.19376355  |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.00508    |\n",
            "|    n_updates            | 120         |\n",
            "|    policy_gradient_loss | -0.00732    |\n",
            "|    value_loss           | 0.00401     |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 630         |\n",
            "|    iterations           | 14          |\n",
            "|    time_elapsed         | 181         |\n",
            "|    total_timesteps      | 114688      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010919945 |\n",
            "|    clip_fraction        | 0.133       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.71       |\n",
            "|    explained_variance   | 0.25413764  |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.000105    |\n",
            "|    n_updates            | 130         |\n",
            "|    policy_gradient_loss | -0.00991    |\n",
            "|    value_loss           | 0.00379     |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=120000, episode_reward=0.00 +/- 0.00\n",
            "Episode length: 288.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 288         |\n",
            "|    mean_reward          | 0           |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 120000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010876232 |\n",
            "|    clip_fraction        | 0.146       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.68       |\n",
            "|    explained_variance   | 0.3510443   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.0146      |\n",
            "|    n_updates            | 140         |\n",
            "|    policy_gradient_loss | -0.0114     |\n",
            "|    value_loss           | 0.00726     |\n",
            "-----------------------------------------\n",
            "-------------------------------\n",
            "| time/              |        |\n",
            "|    fps             | 625    |\n",
            "|    iterations      | 15     |\n",
            "|    time_elapsed    | 196    |\n",
            "|    total_timesteps | 122880 |\n",
            "-------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 625         |\n",
            "|    iterations           | 16          |\n",
            "|    time_elapsed         | 209         |\n",
            "|    total_timesteps      | 131072      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012056114 |\n",
            "|    clip_fraction        | 0.157       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.64       |\n",
            "|    explained_variance   | 0.3590132   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.02       |\n",
            "|    n_updates            | 150         |\n",
            "|    policy_gradient_loss | -0.0156     |\n",
            "|    value_loss           | 0.0131      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 625          |\n",
            "|    iterations           | 17           |\n",
            "|    time_elapsed         | 222          |\n",
            "|    total_timesteps      | 139264       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0145801455 |\n",
            "|    clip_fraction        | 0.174        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.63        |\n",
            "|    explained_variance   | 0.46198517   |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.00154      |\n",
            "|    n_updates            | 160          |\n",
            "|    policy_gradient_loss | -0.0173      |\n",
            "|    value_loss           | 0.0152       |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 624         |\n",
            "|    iterations           | 18          |\n",
            "|    time_elapsed         | 236         |\n",
            "|    total_timesteps      | 147456      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.014335173 |\n",
            "|    clip_fraction        | 0.187       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.55       |\n",
            "|    explained_variance   | 0.5901977   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0204     |\n",
            "|    n_updates            | 170         |\n",
            "|    policy_gradient_loss | -0.0197     |\n",
            "|    value_loss           | 0.0172      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 624         |\n",
            "|    iterations           | 19          |\n",
            "|    time_elapsed         | 249         |\n",
            "|    total_timesteps      | 155648      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.017824344 |\n",
            "|    clip_fraction        | 0.188       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.47       |\n",
            "|    explained_variance   | 0.5913085   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0134     |\n",
            "|    n_updates            | 180         |\n",
            "|    policy_gradient_loss | -0.0184     |\n",
            "|    value_loss           | 0.0172      |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=160000, episode_reward=0.20 +/- 0.39\n",
            "Episode length: 231.40 +/- 113.20\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 231         |\n",
            "|    mean_reward          | 0.197       |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 160000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.016542895 |\n",
            "|    clip_fraction        | 0.206       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.41       |\n",
            "|    explained_variance   | 0.62168175  |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0214     |\n",
            "|    n_updates            | 190         |\n",
            "|    policy_gradient_loss | -0.0216     |\n",
            "|    value_loss           | 0.0126      |\n",
            "-----------------------------------------\n",
            "New best mean reward!\n",
            "-------------------------------\n",
            "| time/              |        |\n",
            "|    fps             | 621    |\n",
            "|    iterations      | 20     |\n",
            "|    time_elapsed    | 263    |\n",
            "|    total_timesteps | 163840 |\n",
            "-------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 620        |\n",
            "|    iterations           | 21         |\n",
            "|    time_elapsed         | 277        |\n",
            "|    total_timesteps      | 172032     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.02087401 |\n",
            "|    clip_fraction        | 0.257      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -1.26      |\n",
            "|    explained_variance   | 0.6308327  |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | -0.0217    |\n",
            "|    n_updates            | 200        |\n",
            "|    policy_gradient_loss | -0.0244    |\n",
            "|    value_loss           | 0.00944    |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 620         |\n",
            "|    iterations           | 22          |\n",
            "|    time_elapsed         | 290         |\n",
            "|    total_timesteps      | 180224      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.018078104 |\n",
            "|    clip_fraction        | 0.217       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.1        |\n",
            "|    explained_variance   | 0.50829476  |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0204     |\n",
            "|    n_updates            | 210         |\n",
            "|    policy_gradient_loss | -0.02       |\n",
            "|    value_loss           | 0.00695     |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 619         |\n",
            "|    iterations           | 23          |\n",
            "|    time_elapsed         | 303         |\n",
            "|    total_timesteps      | 188416      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.022436153 |\n",
            "|    clip_fraction        | 0.253       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1          |\n",
            "|    explained_variance   | 0.57958525  |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0131     |\n",
            "|    n_updates            | 220         |\n",
            "|    policy_gradient_loss | -0.0217     |\n",
            "|    value_loss           | 0.00417     |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 619         |\n",
            "|    iterations           | 24          |\n",
            "|    time_elapsed         | 317         |\n",
            "|    total_timesteps      | 196608      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.018452736 |\n",
            "|    clip_fraction        | 0.216       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.831      |\n",
            "|    explained_variance   | 0.5598315   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0188     |\n",
            "|    n_updates            | 230         |\n",
            "|    policy_gradient_loss | -0.0195     |\n",
            "|    value_loss           | 0.00272     |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=200000, episode_reward=0.96 +/- 0.02\n",
            "Episode length: 11.40 +/- 5.99\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 11.4        |\n",
            "|    mean_reward          | 0.964       |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 200000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.018571522 |\n",
            "|    clip_fraction        | 0.174       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.708      |\n",
            "|    explained_variance   | 0.6463182   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0315     |\n",
            "|    n_updates            | 240         |\n",
            "|    policy_gradient_loss | -0.0169     |\n",
            "|    value_loss           | 0.0021      |\n",
            "-----------------------------------------\n",
            "New best mean reward!\n",
            "Stopping training because the mean reward 0.96  is above the threshold 0.95\n",
            "Running experiment with vf_coef = 1.0, iteration 3\n",
            "Observation space: Box(0, 255, (3, 7, 7), uint8)\n",
            "Observation space shape: (3, 7, 7)\n",
            "Using cpu device\n",
            "Logging to ./ppo_minigrid_tensorboard/vf_coef_1.0/PPO_3\n",
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    fps             | 1884 |\n",
            "|    iterations      | 1    |\n",
            "|    time_elapsed    | 4    |\n",
            "|    total_timesteps | 8192 |\n",
            "-----------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 913          |\n",
            "|    iterations           | 2            |\n",
            "|    time_elapsed         | 17           |\n",
            "|    total_timesteps      | 16384        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.009069766  |\n",
            "|    clip_fraction        | 0.032        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.94        |\n",
            "|    explained_variance   | -0.008497953 |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.0158      |\n",
            "|    n_updates            | 10           |\n",
            "|    policy_gradient_loss | -0.00237     |\n",
            "|    value_loss           | 0.000965     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 781         |\n",
            "|    iterations           | 3           |\n",
            "|    time_elapsed         | 31          |\n",
            "|    total_timesteps      | 24576       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009330324 |\n",
            "|    clip_fraction        | 0.0823      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.93       |\n",
            "|    explained_variance   | -1.2727523  |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.00176    |\n",
            "|    n_updates            | 20          |\n",
            "|    policy_gradient_loss | -0.00645    |\n",
            "|    value_loss           | 1.97e-05    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 725         |\n",
            "|    iterations           | 4           |\n",
            "|    time_elapsed         | 45          |\n",
            "|    total_timesteps      | 32768       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007813768 |\n",
            "|    clip_fraction        | 0.0952      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.93       |\n",
            "|    explained_variance   | 0.021131516 |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.0172      |\n",
            "|    n_updates            | 30          |\n",
            "|    policy_gradient_loss | -0.00421    |\n",
            "|    value_loss           | 0.00172     |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=40000, episode_reward=0.00 +/- 0.00\n",
            "Episode length: 288.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 288         |\n",
            "|    mean_reward          | 0           |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 40000       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007713128 |\n",
            "|    clip_fraction        | 0.0755      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.9        |\n",
            "|    explained_variance   | 0.12758994  |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0116     |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.00485    |\n",
            "|    value_loss           | 0.00122     |\n",
            "-----------------------------------------\n",
            "New best mean reward!\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    fps             | 681   |\n",
            "|    iterations      | 5     |\n",
            "|    time_elapsed    | 60    |\n",
            "|    total_timesteps | 40960 |\n",
            "------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 668          |\n",
            "|    iterations           | 6            |\n",
            "|    time_elapsed         | 73           |\n",
            "|    total_timesteps      | 49152        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0116470065 |\n",
            "|    clip_fraction        | 0.128        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.89        |\n",
            "|    explained_variance   | -0.10294545  |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.0256      |\n",
            "|    n_updates            | 50           |\n",
            "|    policy_gradient_loss | -0.0102      |\n",
            "|    value_loss           | 0.000463     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 659         |\n",
            "|    iterations           | 7           |\n",
            "|    time_elapsed         | 86          |\n",
            "|    total_timesteps      | 57344       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009227812 |\n",
            "|    clip_fraction        | 0.0977      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.88       |\n",
            "|    explained_variance   | 0.3084429   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.00899     |\n",
            "|    n_updates            | 60          |\n",
            "|    policy_gradient_loss | -0.0073     |\n",
            "|    value_loss           | 0.00233     |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 653         |\n",
            "|    iterations           | 8           |\n",
            "|    time_elapsed         | 100         |\n",
            "|    total_timesteps      | 65536       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011490364 |\n",
            "|    clip_fraction        | 0.136       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.85       |\n",
            "|    explained_variance   | 0.3118999   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0111     |\n",
            "|    n_updates            | 70          |\n",
            "|    policy_gradient_loss | -0.00888    |\n",
            "|    value_loss           | 0.00256     |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 646         |\n",
            "|    iterations           | 9           |\n",
            "|    time_elapsed         | 114         |\n",
            "|    total_timesteps      | 73728       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011957704 |\n",
            "|    clip_fraction        | 0.145       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.8        |\n",
            "|    explained_variance   | 0.31021756  |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.00178    |\n",
            "|    n_updates            | 80          |\n",
            "|    policy_gradient_loss | -0.0099     |\n",
            "|    value_loss           | 0.0058      |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=80000, episode_reward=0.00 +/- 0.00\n",
            "Episode length: 288.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 288         |\n",
            "|    mean_reward          | 0           |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 80000       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010309856 |\n",
            "|    clip_fraction        | 0.109       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.8        |\n",
            "|    explained_variance   | 0.3442164   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.0161      |\n",
            "|    n_updates            | 90          |\n",
            "|    policy_gradient_loss | -0.009      |\n",
            "|    value_loss           | 0.00949     |\n",
            "-----------------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    fps             | 636   |\n",
            "|    iterations      | 10    |\n",
            "|    time_elapsed    | 128   |\n",
            "|    total_timesteps | 81920 |\n",
            "------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 634         |\n",
            "|    iterations           | 11          |\n",
            "|    time_elapsed         | 142         |\n",
            "|    total_timesteps      | 90112       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010901324 |\n",
            "|    clip_fraction        | 0.132       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.75       |\n",
            "|    explained_variance   | 0.45231098  |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.00348     |\n",
            "|    n_updates            | 100         |\n",
            "|    policy_gradient_loss | -0.0125     |\n",
            "|    value_loss           | 0.0135      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 633         |\n",
            "|    iterations           | 12          |\n",
            "|    time_elapsed         | 155         |\n",
            "|    total_timesteps      | 98304       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013349486 |\n",
            "|    clip_fraction        | 0.177       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.73       |\n",
            "|    explained_variance   | 0.46122175  |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.017       |\n",
            "|    n_updates            | 110         |\n",
            "|    policy_gradient_loss | -0.018      |\n",
            "|    value_loss           | 0.0194      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 632         |\n",
            "|    iterations           | 13          |\n",
            "|    time_elapsed         | 168         |\n",
            "|    total_timesteps      | 106496      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.015514227 |\n",
            "|    clip_fraction        | 0.193       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.64       |\n",
            "|    explained_variance   | 0.5606079   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0129     |\n",
            "|    n_updates            | 120         |\n",
            "|    policy_gradient_loss | -0.0194     |\n",
            "|    value_loss           | 0.0183      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 630         |\n",
            "|    iterations           | 14          |\n",
            "|    time_elapsed         | 181         |\n",
            "|    total_timesteps      | 114688      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.018560987 |\n",
            "|    clip_fraction        | 0.233       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.55       |\n",
            "|    explained_variance   | 0.58385307  |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0122     |\n",
            "|    n_updates            | 130         |\n",
            "|    policy_gradient_loss | -0.0212     |\n",
            "|    value_loss           | 0.0172      |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=120000, episode_reward=0.19 +/- 0.39\n",
            "Episode length: 232.40 +/- 111.20\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 232         |\n",
            "|    mean_reward          | 0.194       |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 120000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.020042615 |\n",
            "|    clip_fraction        | 0.245       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.5        |\n",
            "|    explained_variance   | 0.6767812   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0242     |\n",
            "|    n_updates            | 140         |\n",
            "|    policy_gradient_loss | -0.0225     |\n",
            "|    value_loss           | 0.0114      |\n",
            "-----------------------------------------\n",
            "New best mean reward!\n",
            "-------------------------------\n",
            "| time/              |        |\n",
            "|    fps             | 625    |\n",
            "|    iterations      | 15     |\n",
            "|    time_elapsed    | 196    |\n",
            "|    total_timesteps | 122880 |\n",
            "-------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 623        |\n",
            "|    iterations           | 16         |\n",
            "|    time_elapsed         | 210        |\n",
            "|    total_timesteps      | 131072     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01946685 |\n",
            "|    clip_fraction        | 0.287      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -1.37      |\n",
            "|    explained_variance   | 0.6089158  |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | -0.0582    |\n",
            "|    n_updates            | 150        |\n",
            "|    policy_gradient_loss | -0.0258    |\n",
            "|    value_loss           | 0.00797    |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 618         |\n",
            "|    iterations           | 17          |\n",
            "|    time_elapsed         | 225         |\n",
            "|    total_timesteps      | 139264      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.020124057 |\n",
            "|    clip_fraction        | 0.25        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.27       |\n",
            "|    explained_variance   | 0.5211112   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.0164      |\n",
            "|    n_updates            | 160         |\n",
            "|    policy_gradient_loss | -0.0202     |\n",
            "|    value_loss           | 0.00578     |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 617         |\n",
            "|    iterations           | 18          |\n",
            "|    time_elapsed         | 238         |\n",
            "|    total_timesteps      | 147456      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.021728639 |\n",
            "|    clip_fraction        | 0.274       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.15       |\n",
            "|    explained_variance   | 0.54098946  |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.046      |\n",
            "|    n_updates            | 170         |\n",
            "|    policy_gradient_loss | -0.0218     |\n",
            "|    value_loss           | 0.00287     |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 617         |\n",
            "|    iterations           | 19          |\n",
            "|    time_elapsed         | 252         |\n",
            "|    total_timesteps      | 155648      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.027604666 |\n",
            "|    clip_fraction        | 0.298       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.96       |\n",
            "|    explained_variance   | 0.59584284  |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0376     |\n",
            "|    n_updates            | 180         |\n",
            "|    policy_gradient_loss | -0.025      |\n",
            "|    value_loss           | 0.00214     |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=160000, episode_reward=0.78 +/- 0.39\n",
            "Episode length: 65.00 +/- 111.51\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 65          |\n",
            "|    mean_reward          | 0.777       |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 160000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.028214619 |\n",
            "|    clip_fraction        | 0.266       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.806      |\n",
            "|    explained_variance   | 0.6637461   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0246     |\n",
            "|    n_updates            | 190         |\n",
            "|    policy_gradient_loss | -0.0224     |\n",
            "|    value_loss           | 0.00166     |\n",
            "-----------------------------------------\n",
            "New best mean reward!\n",
            "-------------------------------\n",
            "| time/              |        |\n",
            "|    fps             | 617    |\n",
            "|    iterations      | 20     |\n",
            "|    time_elapsed    | 265    |\n",
            "|    total_timesteps | 163840 |\n",
            "-------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 616         |\n",
            "|    iterations           | 21          |\n",
            "|    time_elapsed         | 278         |\n",
            "|    total_timesteps      | 172032      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.024427596 |\n",
            "|    clip_fraction        | 0.188       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.639      |\n",
            "|    explained_variance   | 0.6592485   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.0382      |\n",
            "|    n_updates            | 200         |\n",
            "|    policy_gradient_loss | -0.015      |\n",
            "|    value_loss           | 0.00104     |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 616        |\n",
            "|    iterations           | 22         |\n",
            "|    time_elapsed         | 292        |\n",
            "|    total_timesteps      | 180224     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.03297469 |\n",
            "|    clip_fraction        | 0.159      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.469     |\n",
            "|    explained_variance   | 0.6642316  |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | -0.0309    |\n",
            "|    n_updates            | 210        |\n",
            "|    policy_gradient_loss | -0.0107    |\n",
            "|    value_loss           | 0.000624   |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 616        |\n",
            "|    iterations           | 23         |\n",
            "|    time_elapsed         | 305        |\n",
            "|    total_timesteps      | 188416     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.05490821 |\n",
            "|    clip_fraction        | 0.151      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.372     |\n",
            "|    explained_variance   | 0.6277101  |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | -0.022     |\n",
            "|    n_updates            | 220        |\n",
            "|    policy_gradient_loss | -0.00541   |\n",
            "|    value_loss           | 0.000794   |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 616        |\n",
            "|    iterations           | 24         |\n",
            "|    time_elapsed         | 318        |\n",
            "|    total_timesteps      | 196608     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.0563883  |\n",
            "|    clip_fraction        | 0.166      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.331     |\n",
            "|    explained_variance   | 0.66226786 |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | -0.0218    |\n",
            "|    n_updates            | 230        |\n",
            "|    policy_gradient_loss | -0.00645   |\n",
            "|    value_loss           | 0.000683   |\n",
            "----------------------------------------\n",
            "Eval num_timesteps=200000, episode_reward=0.77 +/- 0.39\n",
            "Episode length: 65.80 +/- 111.12\n",
            "----------------------------------------\n",
            "| eval/                   |            |\n",
            "|    mean_ep_length       | 65.8       |\n",
            "|    mean_reward          | 0.774      |\n",
            "| time/                   |            |\n",
            "|    total_timesteps      | 200000     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.07467398 |\n",
            "|    clip_fraction        | 0.327      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.415     |\n",
            "|    explained_variance   | 0.10539633 |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | -0.0336    |\n",
            "|    n_updates            | 240        |\n",
            "|    policy_gradient_loss | -0.024     |\n",
            "|    value_loss           | 0.00186    |\n",
            "----------------------------------------\n",
            "-------------------------------\n",
            "| time/              |        |\n",
            "|    fps             | 615    |\n",
            "|    iterations      | 25     |\n",
            "|    time_elapsed    | 332    |\n",
            "|    total_timesteps | 204800 |\n",
            "-------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 615        |\n",
            "|    iterations           | 26         |\n",
            "|    time_elapsed         | 345        |\n",
            "|    total_timesteps      | 212992     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.06419721 |\n",
            "|    clip_fraction        | 0.246      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.367     |\n",
            "|    explained_variance   | 0.38557094 |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | -0.0159    |\n",
            "|    n_updates            | 250        |\n",
            "|    policy_gradient_loss | -0.0203    |\n",
            "|    value_loss           | 0.00188    |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 615         |\n",
            "|    iterations           | 27          |\n",
            "|    time_elapsed         | 359         |\n",
            "|    total_timesteps      | 221184      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.031877153 |\n",
            "|    clip_fraction        | 0.161       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.294      |\n",
            "|    explained_variance   | 0.5802567   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0185     |\n",
            "|    n_updates            | 260         |\n",
            "|    policy_gradient_loss | -0.00958    |\n",
            "|    value_loss           | 0.000903    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 615         |\n",
            "|    iterations           | 28          |\n",
            "|    time_elapsed         | 372         |\n",
            "|    total_timesteps      | 229376      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.035657845 |\n",
            "|    clip_fraction        | 0.146       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.264      |\n",
            "|    explained_variance   | 0.6185216   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.00758    |\n",
            "|    n_updates            | 270         |\n",
            "|    policy_gradient_loss | -0.00798    |\n",
            "|    value_loss           | 0.000924    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 615         |\n",
            "|    iterations           | 29          |\n",
            "|    time_elapsed         | 386         |\n",
            "|    total_timesteps      | 237568      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.056701116 |\n",
            "|    clip_fraction        | 0.171       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.262      |\n",
            "|    explained_variance   | 0.6490992   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0272     |\n",
            "|    n_updates            | 280         |\n",
            "|    policy_gradient_loss | 0.0212      |\n",
            "|    value_loss           | 0.000525    |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=240000, episode_reward=0.97 +/- 0.01\n",
            "Episode length: 8.00 +/- 2.28\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 8           |\n",
            "|    mean_reward          | 0.975       |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 240000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.057194352 |\n",
            "|    clip_fraction        | 0.219       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.28       |\n",
            "|    explained_variance   | 0.40117508  |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0278     |\n",
            "|    n_updates            | 290         |\n",
            "|    policy_gradient_loss | -0.0264     |\n",
            "|    value_loss           | 0.00116     |\n",
            "-----------------------------------------\n",
            "New best mean reward!\n",
            "Stopping training because the mean reward 0.97  is above the threshold 0.95\n",
            "All experiments completed.\n"
          ]
        }
      ],
      "source": [
        "def run_experiment(vf_coef):\n",
        "    try:\n",
        "        env = DummyVecEnv([make_env() for _ in range(4)])\n",
        "        env = VecTransposeImage(env)\n",
        "\n",
        "        print(\"Observation space:\", env.observation_space)\n",
        "        print(\"Observation space shape:\", env.observation_space.shape)\n",
        "\n",
        "        model = PPO(\"CnnPolicy\", env, verbose=1, tensorboard_log=f\"./ppo_minigrid_tensorboard/vf_coef_{vf_coef}/\",\n",
        "                    vf_coef=vf_coef, policy_kwargs=policy_kwargs)\n",
        "\n",
        "        eval_env = VecTransposeImage(DummyVecEnv([make_env()]))\n",
        "        stop_callback = StopTrainingOnRewardThreshold(reward_threshold=0.95, verbose=1)\n",
        "        eval_callback = EvalCallback(eval_env, callback_on_new_best=stop_callback, eval_freq=10000,\n",
        "                                     best_model_save_path=f\"./logs/vf_coef_{vf_coef}/\",\n",
        "                                     log_path=f\"./logs/vf_coef_{vf_coef}/\", n_eval_episodes=5)\n",
        "\n",
        "        model.learn(total_timesteps=500000, callback=eval_callback)\n",
        "        model.save(f\"ppo_minigrid_unlock_vf_coef_{vf_coef}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {str(e)}\")\n",
        "    finally:\n",
        "        if 'env' in locals():\n",
        "            env.close()\n",
        "\n",
        "vf_coef_values = [0.5, 0.75, 1.0]\n",
        "for vf_coef in vf_coef_values:\n",
        "    for i in range(3):\n",
        "        print(f\"Running experiment with vf_coef = {vf_coef}, iteration {i+1}\")\n",
        "        run_experiment(vf_coef)\n",
        "\n",
        "print(\"All experiments completed.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PPO Parameter Tuning Experiment\n",
        "\n",
        "In this experiment, we tune the value of the `vf_coef` parameter for the PPO algorithm in a MiniGrid environment. The three values we used for `vf_coef` are:\n",
        "- **1.0** (high emphasis on value function loss)\n",
        "- **0.75** (moderate emphasis)\n",
        "- **0.5** (lower emphasis)\n",
        "\n",
        "We trained the model for a total of 100,000 timesteps and logged the rewards obtained at each timestep.\n"
      ],
      "metadata": {
        "id": "uil5GCGz3wL-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Collecting TensorBoard Plots\n",
        "To collect plots we used on terminal:\n",
        "\n",
        "> tensorboard --logdir ./ppo_minigrid_tensorboard\n",
        "\n",
        "And then downloaded the data, which we analyze and plot the results\n"
      ],
      "metadata": {
        "id": "_hgbEbR50o06"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "u5Rgal8z0r_D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analyzing the data"
      ],
      "metadata": {
        "id": "eDBT8gMb0UGK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reward"
      ],
      "metadata": {
        "id": "wvT6gwqF2WCS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_1_reward = pd.read_csv('/content/vf_coef_1.0_PPO_3 (3).csv')\n",
        "df_0_75_reward = pd.read_csv('/content/vf_coef_0.75_PPO_3 (1).csv')\n",
        "df_0_5_reward = pd.read_csv('/content/vf_coef_0.5_PPO_3.csv')\n",
        "df_0_5_reward.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "1lfAj4e12XNK",
        "outputId": "f4f150a4-8ca8-4d36-c7a5-c51177f36790"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Wall time    Step     Value\n",
              "0  1.727525e+09   40000  0.000000\n",
              "1  1.727525e+09   80000  0.000000\n",
              "2  1.727526e+09  120000  0.000000\n",
              "3  1.727526e+09  160000  0.000000\n",
              "4  1.727526e+09  200000  0.194375"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b067482a-e46d-42c2-b565-315cbb14d5cd\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Wall time</th>\n",
              "      <th>Step</th>\n",
              "      <th>Value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.727525e+09</td>\n",
              "      <td>40000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.727525e+09</td>\n",
              "      <td>80000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.727526e+09</td>\n",
              "      <td>120000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.727526e+09</td>\n",
              "      <td>160000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.727526e+09</td>\n",
              "      <td>200000</td>\n",
              "      <td>0.194375</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b067482a-e46d-42c2-b565-315cbb14d5cd')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b067482a-e46d-42c2-b565-315cbb14d5cd button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b067482a-e46d-42c2-b565-315cbb14d5cd');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3ef6cc25-61f4-4b8c-bff4-34d558a3df66\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3ef6cc25-61f4-4b8c-bff4-34d558a3df66')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3ef6cc25-61f4-4b8c-bff4-34d558a3df66 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_0_5_reward",
              "summary": "{\n  \"name\": \"df_0_5_reward\",\n  \"rows\": 7,\n  \"fields\": [\n    {\n      \"column\": \"Wall time\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 142.80689206264373,\n        \"min\": 1727525368.0056226,\n        \"max\": 1727525764.3739164,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          1727525368.0056226,\n          1727525434.7806523,\n          1727525699.2375257\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Step\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 86409,\n        \"min\": 40000,\n        \"max\": 280000,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          40000,\n          80000,\n          240000\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Value\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4069052249565962,\n        \"min\": 0.0,\n        \"max\": 0.9537500143051147,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.1943750083446502,\n          0.9537500143051147,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "# Plot for vf_coef 1.0\n",
        "plt.plot(df_1_reward['Step'], df_1_reward['Value'], label='vf_coef = 1.0')\n",
        "\n",
        "# Plot for vf_coef 0.75\n",
        "plt.plot(df_0_75_reward['Step'], df_0_75_reward['Value'], label='vf_coef = 0.75')\n",
        "\n",
        "# Plot for vf_coef 0.5\n",
        "plt.plot(df_0_5_reward['Step'], df_0_5_reward['Value'], label='vf_coef = 0.5')\n",
        "\n",
        "plt.title('PPO Training Reward for Different vf_coef Values')\n",
        "plt.xlabel('Timesteps')\n",
        "plt.ylabel('Reward')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 718
        },
        "id": "0TvcS5dV2z_4",
        "outputId": "6cf52a1d-d376-4411-e7cb-65522f882eac"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training Loss"
      ],
      "metadata": {
        "id": "-2bQCrGY2UiN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lEeU9JuTy8uv",
        "outputId": "8f593448-26a4-46d6-e876-346e61913acb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data for vf_coef 1.0:\n",
            "      Wall time    Step       Value\n",
            "0  1.727528e+09   40000  288.000000\n",
            "1  1.727528e+09   80000  288.000000\n",
            "2  1.727528e+09  120000  232.399994\n",
            "3  1.727528e+09  160000   65.000000\n",
            "4  1.727528e+09  200000   65.800003\n",
            "\n",
            "Data for vf_coef 0.75:\n",
            "      Wall time    Step  Value\n",
            "0  1.727527e+09   40000  288.0\n",
            "1  1.727527e+09   80000  288.0\n",
            "2  1.727527e+09  120000  288.0\n",
            "3  1.727527e+09  160000  288.0\n",
            "4  1.727527e+09  200000  177.0\n",
            "\n",
            "Data for vf_coef 0.5:\n",
            "      Wall time   Step     Value\n",
            "0  1.727525e+09  16384  0.000027\n",
            "1  1.727525e+09  24576  0.000022\n",
            "2  1.727525e+09  32768  0.000018\n",
            "3  1.727525e+09  40000  0.000773\n",
            "4  1.727525e+09  49152  0.000018\n"
          ]
        }
      ],
      "source": [
        "data_1_0 = pd.read_csv('/content/vf_coef_1.0_PPO_3.csv')\n",
        "data_0_75 = pd.read_csv('/content/vf_coef_0.75_PPO_3.csv')\n",
        "data_0_5 = pd.read_csv('/content/vf_coef_0.5_PPO_1.csv')\n",
        "\n",
        "print(\"Data for vf_coef 1.0:\")\n",
        "print(data_1_0.head())\n",
        "\n",
        "print(\"\\nData for vf_coef 0.75:\")\n",
        "print(data_0_75.head())\n",
        "\n",
        "print(\"\\nData for vf_coef 0.5:\")\n",
        "print(data_0_5.head())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_1_0.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "JH0PfNvM15Ra",
        "outputId": "38a90dc9-3335-409d-9edd-2a34990c0dd1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Wall time    Step       Value\n",
              "0  1.727528e+09   40000  288.000000\n",
              "1  1.727528e+09   80000  288.000000\n",
              "2  1.727528e+09  120000  232.399994\n",
              "3  1.727528e+09  160000   65.000000\n",
              "4  1.727528e+09  200000   65.800003"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-30594973-b323-4c89-8b8c-64ced36845b4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Wall time</th>\n",
              "      <th>Step</th>\n",
              "      <th>Value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.727528e+09</td>\n",
              "      <td>40000</td>\n",
              "      <td>288.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.727528e+09</td>\n",
              "      <td>80000</td>\n",
              "      <td>288.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.727528e+09</td>\n",
              "      <td>120000</td>\n",
              "      <td>232.399994</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.727528e+09</td>\n",
              "      <td>160000</td>\n",
              "      <td>65.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.727528e+09</td>\n",
              "      <td>200000</td>\n",
              "      <td>65.800003</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-30594973-b323-4c89-8b8c-64ced36845b4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-30594973-b323-4c89-8b8c-64ced36845b4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-30594973-b323-4c89-8b8c-64ced36845b4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-34b76e13-ee3a-4727-980a-7f320d412c57\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-34b76e13-ee3a-4727-980a-7f320d412c57')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-34b76e13-ee3a-4727-980a-7f320d412c57 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data_1_0",
              "summary": "{\n  \"name\": \"data_1_0\",\n  \"rows\": 6,\n  \"fields\": [\n    {\n      \"column\": \"Wall time\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 126.30108585245117,\n        \"min\": 1727527768.821,\n        \"max\": 1727528106.407309,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          1727527768.821,\n          1727527836.9676309,\n          1727528106.407309\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Step\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 74833,\n        \"min\": 40000,\n        \"max\": 240000,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          40000,\n          80000,\n          240000\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Value\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 125.68619006205282,\n        \"min\": 8.0,\n        \"max\": 288.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          232.3999938964844,\n          8.0,\n          65.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "# Plot for vf_coef 1.0\n",
        "plt.plot(data_1_0['Step'], data_1_0['Value'], label='vf_coef = 1.0')\n",
        "\n",
        "# Plot for vf_coef 0.75\n",
        "plt.plot(data_0_75['Step'], data_0_75['Value'], label='vf_coef = 0.75')\n",
        "\n",
        "# Plot for vf_coef 0.5\n",
        "plt.plot(data_0_5['Step'], data_0_5['Value'], label='vf_coef = 0.5')\n",
        "\n",
        "plt.title('PPO Training Loss for Different vf_coef Values')\n",
        "plt.xlabel('Timesteps')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 718
        },
        "id": "ZRqfJ4Tp0aEe",
        "outputId": "4c957589-a94f-481f-9dc3-31c5e9c191ef"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Results Analysis\n",
        "\n",
        "The plot above shows the training rewards obtained by the PPO agent over time for different `vf_coef` values.\n",
        "\n",
        "- **vf_coef = 1.0:** This setting emphasizes the value function loss significantly, leading to rapid improvement in rewards.\n",
        "- **vf_coef = 0.75:** This value provides a balance between exploration and exploitation, resulting in consistent performance.\n",
        "- **vf_coef = 0.5:** With the least emphasis on the value function loss, the model exhibits slower improvement, indicating that a lower `vf_coef` may not leverage the value function as effectively in this context.\n",
        "\n",
        "Overall, adjusting the `vf_coef` parameter plays a crucial role in the training dynamics and performance of the PPO agent in MiniGrid environments.\n"
      ],
      "metadata": {
        "id": "qX0K5IsU3dBV"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "veSxbqEn1POG"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "ppo_minigrid",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}